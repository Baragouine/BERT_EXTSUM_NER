{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Bert for extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import statistics\n",
    "import os\n",
    "from utils.split_all_docs import split_all_docs\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.DataLoader import DataLoader\n",
    "from utils.preprocess_df import preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "  try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "      return True   # Jupyter notebook or qtconsole\n",
    "    elif shell == 'TerminalInteractiveShell':\n",
    "      return False  # Terminal running IPython\n",
    "    else:\n",
    "      return False  # Other type (?)\n",
    "  except NameError:\n",
    "    return False      # Probably standard Python interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse args if script mode\n",
    "parser = argparse.ArgumentParser(description='extractive summary and ner using bert')\n",
    "\n",
    "parser.add_argument('-is_graphic',type=int,default=1,choices=[0,1])\n",
    "parser.add_argument('-gpu_num',type=int,default=0)\n",
    "parser.add_argument('-batch_size',type=int,default=4)#32)\n",
    "parser.add_argument('-epochs',type=int,default=100)\n",
    "parser.add_argument('-dataset',type=str,default=\"data/wiki_geo_ratio_sc_0.5.json\")\n",
    "parser.add_argument('-doc_column_name',type=str,default=\"flat_contents\")\n",
    "parser.add_argument('-labels_sum_column_name',type=str,default=\"labels_sentences\")\n",
    "parser.add_argument('-labels_ner_column_name',type=str,default=\"labels_entities\")\n",
    "\n",
    "args = None\n",
    "\n",
    "if is_notebook():\n",
    "  args = parser.parse_args(\"\")\n",
    "else:\n",
    "  args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse:\n",
      "is_graphic: True\n",
      "cuda_num: 2\n",
      "epochs 100\n",
      "batch_size 4\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "is_graphic = args.is_graphic != 0\n",
    "cuda_num = args.gpu_num\n",
    "bert_layer = CamembertModel.from_pretrained('camembert-base')\n",
    "bert_tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "# hyper-parameters\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "learning_rate = 1e-3\n",
    "early_stopping = 3\n",
    "model_name = \"02-train_camembert_ext_summary\"\n",
    "sub_folder_name = \"model_name__{}__time__{}__lr__{}__batch_size__{}__cuda_num__{}__early_stopping__{}\".format(model_name, time(), learning_rate, batch_size, cuda_num, early_stopping)\n",
    "checkpoints_folder = \"./checkpoints/\" + sub_folder_name\n",
    "loss_sum_coef = 0.5\n",
    "loss_ner_coef = 0.5\n",
    "average_number_of_sentences_per_document = 3\n",
    "\n",
    "# print\n",
    "print(\"parse:\")\n",
    "print(\"is_graphic:\", is_graphic)\n",
    "print(\"cuda_num:\", cuda_num)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 6\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 2: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 3: NVIDIA GeForce GTX 1080\n",
      "GPU 4: NVIDIA GeForce GTX 1080\n",
      "GPU 5: NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "  # Display the number of available GPUs\n",
    "  print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "  # Display the name of each GPU\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"MPS available.\")\n",
    "else:\n",
    "  print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:\" + str(cuda_num) \n",
    "elif torch.backends.mps.is_available():\n",
    "  dev = torch.device(\"mps\")\n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(l):\n",
    "  return sum(l) / len(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.dataset)\n",
    "df = shuffle(df, random_state=0)\n",
    "\n",
    "df_test = df.iloc[0:1000]\n",
    "df_val = df.iloc[1000:2000]\n",
    "df_train = df.iloc[2000:]#30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats corpus\n",
    "\n",
    "if False:\n",
    "  len_articles = []\n",
    "\n",
    "  for idx in df.index:\n",
    "    txt = df[\"flat_contents\"][idx]\n",
    "    txt = sent_tokenize(txt)\n",
    "    txt = \" [SEP] \".join(txt)\n",
    "    txt = bert_tokenizer.encode(txt, add_special_tokens=False)\n",
    "    len_articles.append(len(txt))\n",
    "\n",
    "  print(\"max:\", max(len_articles), \", mediane:\", statistics.median(len_articles), \", avg:\", average(len_articles), \", std:\", statistics.stdev(len_articles))\n",
    "  # max: 184812 , mediane: 862.5 , avg: 2146.653203237274 , std: 4145.829631357804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>contents</th>\n",
       "      <th>entities</th>\n",
       "      <th>flat_contents</th>\n",
       "      <th>trunc_contents</th>\n",
       "      <th>labels_entities</th>\n",
       "      <th>labels_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>géologie</td>\n",
       "      <td>Sismicité au Japon</td>\n",
       "      <td>La sismicité au Japon est particulièrement imp...</td>\n",
       "      <td>La sismicité au Japon est particulièrement imp...</td>\n",
       "      <td>[10 septembre, 11 mars, 12 janvier, 1399, 1400...</td>\n",
       "      <td>\\n\\n\\n\\nLe Japon est un archipel volcanique, s...</td>\n",
       "      <td>\\n\\n\\n== Plaques et fosses ==\\n\\nLe Japon est ...</td>\n",
       "      <td>[[0, E, 0, 0, E, 0, 0, 0, 0, 0, L, C, C, R, C,...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>géographie générale</td>\n",
       "      <td>Voyage d'études</td>\n",
       "      <td>Voyage d'études est un roman inachevé de l'écr...</td>\n",
       "      <td>Voyage d'études est un roman inachevé de l'écr...</td>\n",
       "      <td>[1905 en littérature, 1991 en littérature, Abe...</td>\n",
       "      <td>\\n\\n\\n\\nEn 1903, Théophile Cart prononce un di...</td>\n",
       "      <td>\\n\\n\\n== Historique ==\\n\\nEn 1903, Théophile C...</td>\n",
       "      <td>[[0, 0, R, C, 0, 0, 0, 0, E, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                categories              titles  \\\n",
       "21430             géologie  Sismicité au Japon   \n",
       "7651   géographie générale     Voyage d'études   \n",
       "\n",
       "                                               summaries  \\\n",
       "21430  La sismicité au Japon est particulièrement imp...   \n",
       "7651   Voyage d'études est un roman inachevé de l'écr...   \n",
       "\n",
       "                                                contents  \\\n",
       "21430  La sismicité au Japon est particulièrement imp...   \n",
       "7651   Voyage d'études est un roman inachevé de l'écr...   \n",
       "\n",
       "                                                entities  \\\n",
       "21430  [10 septembre, 11 mars, 12 janvier, 1399, 1400...   \n",
       "7651   [1905 en littérature, 1991 en littérature, Abe...   \n",
       "\n",
       "                                           flat_contents  \\\n",
       "21430  \\n\\n\\n\\nLe Japon est un archipel volcanique, s...   \n",
       "7651   \\n\\n\\n\\nEn 1903, Théophile Cart prononce un di...   \n",
       "\n",
       "                                          trunc_contents  \\\n",
       "21430  \\n\\n\\n== Plaques et fosses ==\\n\\nLe Japon est ...   \n",
       "7651   \\n\\n\\n== Historique ==\\n\\nEn 1903, Théophile C...   \n",
       "\n",
       "                                         labels_entities  \\\n",
       "21430  [[0, E, 0, 0, E, 0, 0, 0, 0, 0, L, C, C, R, C,...   \n",
       "7651   [[0, 0, R, C, 0, 0, 0, 0, E, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                        labels_sentences  \n",
       "21430  [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...  \n",
       "7651   [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_df(df=df_train, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)\n",
    "val_dataset = preprocess_df(df=df_val, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)\n",
    "test_dataset = preprocess_df(df=df_test, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prop=0.1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertExtSUMNER(nn.Module):\n",
    "  def __init__(self, bert_layer, bert_tokenizer, dim_emb=768) -> None:\n",
    "    super(BertExtSUMNER, self).__init__()\n",
    "    self.bert_layer = bert_layer\n",
    "    self.bert_tokenizer = bert_tokenizer\n",
    "    self.dim_emb = dim_emb\n",
    "\n",
    "    # predict summary\n",
    "    self.w_sum = nn.Linear(dim_emb, 1)\n",
    "    \n",
    "    # NER\n",
    "    self.w_ner = nn.Linear(dim_emb, 1)\n",
    "\n",
    "  def forward(self, list_input_ids, list_attention_mask):\n",
    "    id_sep = bert_tokenizer.sep_token_id\n",
    "    id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in range(len(list_input_ids)):\n",
    "      input_ids.append(list_input_ids[i].to(self.bert_layer.device))\n",
    "      attention_mask.append(list_attention_mask[i].to(self.bert_layer.device))\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "\n",
    "    x = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    mask_sep = (input_ids == id_sep).view(-1)\n",
    "    mask_not_sep = (torch.ne(input_ids, bert_tokenizer.pad_token_id) & torch.ne(input_ids, bert_tokenizer.sep_token_id)).view(-1)\n",
    "    x = x.last_hidden_state\n",
    "    x = x.view(-1, x.size(-1))\n",
    "    emb_sent = x[mask_sep, :]\n",
    "    emb_entities = x[mask_not_sep, :]\n",
    "\n",
    "    o_sum = self.w_sum(emb_sent)\n",
    "    o_sum = torch.sigmoid(o_sum).squeeze(-1)\n",
    "\n",
    "    o_ner = self.w_ner(emb_entities)\n",
    "    o_ner = torch.sigmoid(o_ner).squeeze(-1)\n",
    "\n",
    "    return o_sum, o_ner\n",
    "\n",
    "  def save(self, fname):\n",
    "    torch.save(self.state_dict(), fname)\n",
    "\n",
    "  def load(self, fname):\n",
    "    self.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoints_folder):\n",
    "  os.makedirs(checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2164378/2083174348.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"doc_splitted\"] = split_all_docs(df_val[args.doc_column_name])\n"
     ]
    }
   ],
   "source": [
    "df_val[\"doc_splitted\"] = split_all_docs(df_val[args.doc_column_name])\n",
    "val_set = df_val\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61%|██████    | 3730/6111 [7:06:06<4:58:29,  7.52s/batch, loss=0.0565, loss_sum=0.0565] "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "arr_train_loss = []\n",
    "arr_train_loss_sum = []\n",
    "#arr_train_loss_ner = []\n",
    "#arr_train_acc_sum = []\n",
    "#arr_train_acc_ner = []\n",
    "arr_val_loss = []\n",
    "#arr_val_acc_sum = []\n",
    "#arr_val_acc_ner = []\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  # Train\n",
    "  model.train()\n",
    "  nb_batch_train = 0\n",
    "  nb_loss_train = 0\n",
    "  total_train_loss = 0\n",
    "  total_train_loss_sum = 0\n",
    "  #total_train_loss_ner = 0\n",
    "  #total_train_acc_sum = 0\n",
    "  #total_train_acc_ner = 0\n",
    "  \n",
    "  id_sep = bert_tokenizer.sep_token_id\n",
    "  id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "  for i in range(len(train_loader)):\n",
    "    train_loader[i]\n",
    "\n",
    "  with tqdm(train_loader, unit=\"batch\", total=len(train_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "      tepoch.set_description(f\"Epoch {epoch}\")\n",
    "      #if dev != \"cpu\":\n",
    "      #  torch.cuda.empty_cache()\n",
    "      list_input_ids = batch[\"input_ids\"]\n",
    "      list_attention_mask = batch[\"attention_mask\"]\n",
    "      list_targets_sum = batch[\"labels_sum\"]\n",
    "      #list_targets_ner = batch[\"labels_ner\"]\n",
    "      \n",
    "      list_y_sum_pred = []\n",
    "      #list_y_ner_pred = []\n",
    "      for i in range(len(list_input_ids)):\n",
    "        y_sum_pred, y_ner_pred = model(list_input_ids[i:i+1], list_attention_mask[i:i+1])\n",
    "\n",
    "        loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[i], dtype=torch.float).to(device))\n",
    "        #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[i], dtype=torch.float).to(device))\n",
    "        \n",
    "        #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "        loss = loss_sum\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        nb_loss_train += 1\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_loss_sum += loss_sum.item()\n",
    "        #total_train_loss_ner += loss_ner.item()\n",
    "\n",
    "        list_y_sum_pred.append(y_sum_pred.detach())\n",
    "        #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "      nb_batch_train += 1\n",
    "\n",
    "      y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "      #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "      targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "      #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "      probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "      probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "      #total_train_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "      tepoch.set_postfix(loss=total_train_loss/nb_loss_train, loss_sum=total_train_loss_sum/nb_loss_train)\n",
    "\n",
    "  # Save model\n",
    "  model.save(checkpoints_folder + \"/\" + model_name + \"-\" + str(epoch) + \".pt\")\n",
    "\n",
    "  # Eval\n",
    "  model.eval()\n",
    "  nb_batch_val = 0\n",
    "  nb_loss_val = 0\n",
    "  total_val_loss = 0\n",
    "  total_val_loss_sum = 0\n",
    "  #total_val_loss_ner = 0\n",
    "  #total_val_acc_sum = 0\n",
    "  #total_val_acc_ner = 0\n",
    "  total_r1 = 0\n",
    "  total_r2 = 0\n",
    "  total_rl = 0\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  for i, batch in enumerate(val_loader):\n",
    "    #if dev != \"cpu\":\n",
    "    #  torch.cuda.empty_cache()\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels_sum\"]\n",
    "    list_targets_ner = batch[\"labels_ner\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "      \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      nb_loss_val += 1      \n",
    "      total_val_loss += loss.item()\n",
    "      total_val_loss_sum += loss_sum.item()\n",
    "      #total_val_loss_ner += loss_ner.item()\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    nb_batch_val += 1\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "    #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "    doc = val_set[\"doc_splitted\"].iloc[i]\n",
    "    summaries = val_set[\"summaries\"].iloc[i]\n",
    "\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    doc_lens = [len(doc)]\n",
    "    for j in range(doc_lens[0]):\n",
    "      txt = txt + \". \" + doc[indices[j]]\n",
    "      y_pred_thresh.append(indices[j])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for j in y_pred_thresh:\n",
    "      txt = txt + \". \" + doc[j]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    total_r1 += scores[\"rouge1\"].recall\n",
    "    total_r2 += scores[\"rouge2\"].recall\n",
    "    total_rl += scores[\"rougeL\"].recall\n",
    "\n",
    "    probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #total_val_acc_sum += accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=doc_lens, average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #total_val_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "  print(\"Epoch {} : val loss = {:.3f}, val loss summary = {:.3f}, r1 = {:.3f}, r2 = {:.3f}, rL = {:.3f}\".format(epoch, total_val_loss / nb_loss_val, total_val_loss_sum / nb_loss_val, total_r1 / nb_batch_val, total_r2 / nb_batch_val, total_rl / nb_batch_val))\n",
    "\n",
    "  if len(arr_val_loss) >= early_stopping+1:\n",
    "    if min(arr_val_loss[-early_stopping:]) >= arr_val_loss[-(early_stopping+1)]:\n",
    "      break\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  arr_train_loss.append(total_train_loss / nb_batch_train)\n",
    "  \n",
    "  #arr_train_acc_sum.append(total_train_acc_sum / nb_batch_train)\n",
    "  #arr_train_acc_ner.append(total_train_acc_ner / nb_batch_train)\n",
    "\n",
    "  arr_val_loss.append(total_val_loss / nb_batch_val)\n",
    "  #arr_val_acc_sum.append(total_val_acc_sum / nb_batch_val)\n",
    "  #arr_val_acc_ner.append(total_val_acc_ner / nb_batch_val)\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = {}\n",
    "training_metrics[\"duration\"]   = t2 - t1\n",
    "training_metrics[\"train_loss\"] = arr_train_loss\n",
    "#training_metrics[\"train_acc_sum\"]  = arr_train_acc_sum\n",
    "#training_metrics[\"train_acc_ner\"]  = arr_train_acc_ner\n",
    "training_metrics[\"val_loss\"]   = arr_val_loss\n",
    "#training_metrics[\"val_acc_sum\"]    = arr_val_acc_sum\n",
    "#training_metrics[\"val_acc_ner\"]    = arr_val_acc_ner\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/training_metrics.json\", 'w') as fp:\n",
    "  json.dump(training_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw Losses\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_loss) + 1)), arr_train_loss, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_loss) + 1)), arr_val_loss, label=\"val\")\n",
    "\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_sum) + 1)), arr_train_acc_sum, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_sum) + 1)), arr_val_acc_sum, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy Summary\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_ner) + 1)), arr_train_acc_ner, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_ner) + 1)), arr_val_acc_ner, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy NER\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch = np.argmin(np.array(arr_val_loss)) + 1\n",
    "model.load(checkpoints_folder + \"/\" + model_name + \"-\" + str(best_epoch) + \".pt\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1304026/1937099444.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"doc_splitted\"] = split_all_docs(df_test[args.doc_column_name], False)\n"
     ]
    }
   ],
   "source": [
    "df_test[\"doc_splitted\"] = split_all_docs(df_test[args.doc_column_name], False)\n",
    "test_set = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval model: 100%|██████████| 10/10 [00:05<00:00,  1.79batch/s, loss=1.19e-7, loss_sum=1.19e-7, rouge1=0.239, rouge2=0.0655, rougeL=0.141]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "arr_loss = []\n",
    "arr_loss_sum = []\n",
    "#arr_loss_ner = []\n",
    "#accuracy_sum = []\n",
    "#accuracy_ner = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "counter = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "  for batch in tepoch:\n",
    "    tepoch.set_description(\"Eval model\")\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels_sum\"]\n",
    "    list_targets_ner = batch[\"labels_ner\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "    \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      arr_loss.append(loss.item())\n",
    "      arr_loss_sum.append(loss_sum.item())\n",
    "      #arr_loss_ner.append(loss_ner.item())\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    #targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "    targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "    doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "    summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "    probs = np.array(y_sum_pred.tolist()) # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #probs = threshold_probs_by_nb(probs=probs, doc_lens=[probs.shape[0]], average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #probs = threshold_probs_by_prop(probs=probs, doc_lens=[probs.shape[0]], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document)\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in range(min(len(doc), y_sum_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[indices[i]]\n",
    "      y_pred_thresh.append(indices[i])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in y_pred_thresh:#range(min(len(doc), y_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[i]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "    arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "    arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "    #accuracy_sum.append(accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=[len(probs)], average_number_of_sentences_per_document=average_number_of_sentences_per_document))\n",
    "    #accuracy.append(accuracy_prop_sent_per_doc_fn(probs=probs, targets=targets.cpu().detach().numpy(), doc_lens=[len(probs)], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document))\n",
    "    #accuracy_ner.append(torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0])\n",
    "\n",
    "    tepoch.set_postfix(loss=average(arr_loss), loss_sum=average(arr_loss_sum), rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "#test_metrics[\"accuracy_sum\"] = average(accuracy_sum)\n",
    "#test_metrics[\"accuracy_ner\"] = average(accuracy_ner)\n",
    "test_metrics[\"rouge1\"]   = average(arr_rouge1)\n",
    "test_metrics[\"rouge2\"]   = average(arr_rouge2)\n",
    "test_metrics[\"rougeL\"]   = average(arr_rougeL)\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/test_metrics.json\", 'w') as fp:\n",
    "  json.dump(test_metrics, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lead-3: 100%|██████████| 10/10 [00:00<00:00, 134.57batch/s, rouge1=0.22, rouge2=0.0512, rougeL=0.148]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"Lead-3\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(min(len(doc), 3)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First n char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "First-n-char': 100%|██████████| 10/10 [00:00<00:00, 119.41batch/s, rouge1=0.25, rouge2=0.0622, rougeL=0.156]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"First-n-char'\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(len(doc)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsaid/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Does not execute this cell if you want to execute the following cells.\n",
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(train_dataset[0][\"input_ids\"] == 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][\"labels_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2474, 5715, 9765, 8740, 13926, 1011, 9765, 4241, 17155, 16778, 2078, 1012, 102, 2365, 8945, 12514, 9765, 1037, 1016, 1010, 1019, 2463, 1037, 1048, 1005, 9765, 2139, 3002, 1011, 5578, 1011, 1041, 25394, 3366, 3802, 1037, 1022, 2463, 1037, 1048, 1005, 15068, 4355, 2139, 3347, 21031, 3126, 1012, 102, 3393, 18856, 9581, 2102, 21864, 14418, 21162, 5562, 2474, 5715, 9765, 24209, 11475, 8873, 2063, 1010, 4372, 2230, 1010, 2139, 1077, 18856, 9581, 2102, 4153, 7413, 23151, 2278, 1090, 1010, 7367, 7811, 2474, 5939, 18155, 8649, 2666, 4078, 18856, 9581, 3215, 2139, 2474, 2605, 21864, 4012, 13876, 2063, 2632, 5668, 17504, 2102, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 4372, 12609, 1010, 2474, 5715, 24501, 21748, 2102, 4241, 2828, 1077, 18856, 9581, 2102, 4153, 7413, 1090, 18033, 2474, 5579, 27859, 16558, 2666, 11968, 2777, 8780, 1011, 2605, 1010, 21864, 11265, 4012, 13876, 2063, 4078, 2953, 2863, 2483, 1010, 4372, 6765, 10439, 3217, 5403, 1010, 10861, 25022, 2078, 4160, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 8292, 2828, 2139, 18856, 9581, 2102, 7367, 19817, 4215, 14663, 11968, 4078, 7715, 2079, 18796, 2015, 3802, 16655, 20228, 2226, 25500, 11368, 7373, 5816, 3672, 11113, 29067, 10111, 1006, 4372, 14975, 13642, 2278, 4649, 2566, 20689, 23757, 2015, 2310, 16885, 2139, 1048, 1005, 2012, 5802, 28437, 1007, 1010, 16360, 8445, 2666, 2000, 4904, 8740, 2146, 2139, 1048, 1005, 4776, 2063, 13642, 2278, 4895, 26523, 4555, 1040, 1005, 13323, 16429, 2890, 1037, 10768, 19716, 3771, 1012, 102, 4649, 11498, 11368, 6072, 18856, 9581, 28437, 2015, 21864, 2006, 2102, 2566, 15630, 1040, 1521, 27859, 16558, 4313, 2474, 5939, 18155, 8649, 2666, 2139, 2230, 4012, 6442, 4765, 2416, 10857, 10364, 4649, 7715, 3802, 17504, 2102, 10364, 4649, 13511, 2015, 1010, 2123, 2102, 4649, 10380, 9236, 11370, 1037, 2474, 3671, 2063, 3411, 1011, 2456, 1012, 102, 4649, 17419, 4054, 2229, 10857, 14418, 21162, 29196, 2102, 2474, 5715, 2365, 2102, 2556, 10285, 18033, 1048, 1005, 4372, 3540, 16200, 25022, 1011, 19804, 2229, 1012, 102, 13642, 2278, 3393, 2689, 3672, 18856, 9581, 28437, 1010, 8292, 2015, 10857, 2006, 2102, 23408, 4747, 5657, 1012, 102, 16655, 3802, 12672, 19148, 2063, 4372, 2297, 11968, 2474, 3257, 2236, 2063, 2139, 1048, 1005, 4372, 2121, 11239, 3802, 4241, 18856, 9581, 2102, 3143, 2063, 11968, 4078, 25041, 3164, 2229, 3653, 6767, 4183, 4372, 1041, 16020, 2102, 10861, 2474, 4860, 9587, 20684, 2638, 16475, 14995, 2102, 13675, 28100, 2890, 3802, 2474, 20228, 2226, 25500, 11368, 7373, 9587, 20684, 2638, 21790, 18116, 1010, 13642, 2278, 2000, 10421, 14876, 2483, 2139, 24898, 2015, 8358, 3164, 2229, 1012, 102, 8292, 2015, 2689, 8163, 21877, 27346, 2102, 3802, 2890, 9530, 9153, 4570, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2139, 2777, 8780, 1011, 2605, 2474, 4606, 4013, 5403, 1010, 1077, 2175, 10087, 3077, 1090, 1010, 7505, 2474, 5715, 2139, 2175, 10087, 3077, 1011, 3393, 1996, 4014, 1010, 28616, 2063, 4372, 2326, 4372, 3851, 3802, 21864, 7367, 19817, 7140, 3726, 1037, 1023, 2463, 1037, 5285, 1040, 1005, 1051, 5562, 4887, 1010, 1010, 15068, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 9765, 2139, 2184, 1010, 1021, 6362, 3802, 2474, 18535, 3126, 2139, 13511, 2015, 2139, 6205, 2683, 1010, 1021, 3461, 10364, 2474, 2558, 2063, 3261, 1011, 2230, 1012, 102, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2010, 29469, 4226, 2474, 4606, 4013, 5403, 1010, 1077, 24188, 20431, 1516, 5003, 6279, 8743, 2271, 1090, 1010, 7505, 2474, 5715, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 28616, 2063, 4372, 2326, 4372, 4437, 3802, 1037, 2539, 2463, 1010, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 23408, 4747, 5657, 2139, 2184, 1010, 1018, 6362, 10364, 2474, 2558, 2063, 3411, 1011, 2456, 1037, 2184, 1010, 1021, 6362, 10364, 3261, 1011, 2230, 1010, 16405, 2483, 1037, 2340, 1010, 1015, 6362, 10364, 2889, 1011, 12609, 1012, 102, 13075, 7140, 3077, 9765, 16655, 5715, 3541, 2063, 1010, 2482, 15317, 26208, 2102, 2112, 2666, 4078, 16569, 21877, 2226, 15068, 24403, 21877, 2226, 9742, 2015, 1010, 8740, 12411, 2015, 2139, 2474, 26192, 15029, 2063, 2139, 7939, 28032, 2063, 2139, 1048, 1005, 16021, 4402, 1010, 1010, 1010, 1012, 102, 11968, 9932, 6216, 9236, 2474, 5715, 26208, 2102, 2112, 2666, 2139, 1048, 1005, 2250, 2063, 1040, 1005, 8432, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 2123, 2102, 15317, 9765, 16655, 5715, 2139, 2474, 2522, 21017, 2638, 1012, 102, 8292, 4674, 2250, 2063, 1010, 21864, 19723, 22107, 2063, 6255, 16569, 1010, 9765, 4937, 20265, 29346, 2063, 18033, 4649, 9149, 2139, 2753, 2199, 1037, 25175, 3619, 2139, 3263, 2199, 10427, 11390, 1010, 1012, 102, 1048, 1005, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1010, 2425, 2063, 24209, 1005, 15317, 24501, 21748, 2102, 2139, 2474, 2918, 2139, 2123, 24045, 2015, 2885, 24336, 1040, 1521, 6139, 16012, 21281, 5332, 4226, 4078, 14017, 2015, 2522, 11467, 2455, 3104, 1006, 18856, 2278, 1007, 1010, 9765, 9388, 4226, 2063, 11968, 1048, 1005, 5197, 4078, 26568, 3406, 7442, 2015, 12943, 7277, 29111, 1006, 2531, 1003, 4372, 2760, 1007, 1010, 16655, 10817, 8909, 4765, 7413, 1037, 3526, 2063, 2139, 2901, 1006, 2531, 1003, 1007, 1012, 102, 2474, 16360, 8445, 22753, 6987, 10559, 4372, 2760, 9765, 2474, 24086, 18941, 2063, 1024, 10996, 2015, 1006, 4805, 1003, 1007, 1010, 25170, 2015, 5424, 4244, 1006, 4229, 1010, 1019, 1003, 1007, 1010, 10019, 12943, 7277, 29111, 21770, 10624, 6914, 2229, 1006, 2321, 1010, 1019, 1003, 1007, 1012, 102, 1048, 1005, 16270, 2777, 11968, 9932, 6216, 9236, 1037, 22137, 4895, 2041, 4014, 4372, 5622, 10177, 2566, 11368, 5794, 2102, 2139, 12826, 2099, 1048, 1521, 6622, 18033, 3393, 29023, 2139, 1048, 1521, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1006, 15068, 2139, 26568, 3406, 7442, 2015, 1037, 4078, 14925, 18223, 2229, 2367, 2229, 1007, 1012, 102, 4606, 17301, 2869, 4958, 2080, 10997, 2365, 2102, 7801, 2015, 27411, 2433, 2063, 2139, 11122, 2229, 15068, 7760, 29347, 23144, 5267, 1024, 2474, 11122, 2063, 2139, 16220, 5498, 1006, 16855, 6137, 2063, 9033, 8586, 2571, 1007, 1010, 2474, 11122, 2063, 1040, 1005, 17997, 1011, 2350, 1006, 11102, 1011, 7647, 1007, 3802, 2474, 2558, 2063, 2552, 16284, 2571, 1006, 3925, 1037, 8740, 23099, 4103, 1005, 17504, 1007, 1012, 102, 3393, 2053, 2213, 2139, 2474, 2334, 4221, 9765, 2012, 22199, 2063, 27411, 4649]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nLa commune est au nord-est du Cotentin. Son bourg est à 2,5 km à l'est de Saint-Pierre-Église et à 8 km à l'ouest de Barfleur.\\n\\n\\nLe climat qui caractérise la commune est qualifié, en 2010, de « climat océanique franc », selon la typologie des climats de la France qui compte alors huit grands types de climats en métropole. En 2020, la commune ressort du type « climat océanique » dans la classification établie par Météo-France, qui ne compte désormais, en première approche, que cinq grands types de climats en métropole. Ce type de climat se traduit par des températures douces et une pluviométrie relativement abondante (en liaison avec les perturbations venant de l'Atlantique), répartie tout au long de l'année avec un léger maximum d'octobre à février.\\nLes paramètres climatiques qui ont permis d’établir la typologie de 2010 comportent six variables pour les températures et huit pour les précipitations, dont les valeurs correspondent à la normale 1971-2000. Les sept principales variables caractérisant la commune sont présentées dans l'encadré ci-après.\\n\\nAvec le changement climatique, ces variables ont évolué. Une étude réalisée en 2014 par la Direction générale de l'Énergie et du Climat complétée par des études régionales prévoit en effet que la température moyenne devrait croître et la pluviométrie moyenne baisser, avec toutefois de fortes variations régionales. Ces changements peuvent être constatés sur la station météorologique de Météo-France la plus proche, « Gonneville », sur la commune de Gonneville-Le Theil, mise en service en 1959 et qui se trouve à 9 km à vol d'oiseau,, où la température moyenne annuelle est de 10,7 °C et la hauteur de précipitations de 919,7 mm pour la période 1981-2010.\\nSur la station météorologique historique la plus proche, « Cherbourg – Maupertus », sur la commune de Cherbourg-en-Cotentin, mise en service en 1935 et à 19 km, la température moyenne annuelle évolue de 10,4 °C pour la période 1971-2000 à 10,7 °C pour 1981-2010, puis à 11,1 °C pour 1991-2020.\\n\\n\\n\\n\\nVarouville est une commune rurale, car elle fait partie des communes peu ou très peu denses, au sens de la grille communale de densité de l'Insee,,,.\\nPar ailleurs la commune fait partie de l'aire d'attraction de Cherbourg-en-Cotentin, dont elle est une commune de la couronne. Cette aire, qui regroupe 77 communes, est catégorisée dans les aires de 50 000 à moins de 200 000 habitants,.\\n\\n\\n\\nL'occupation des sols de la commune, telle qu'elle ressort de la base de données européenne d’occupation biophysique des sols Corine Land Cover (CLC), est marquée par l'importance des territoires agricoles (100 % en 2018), une proportion identique à celle de 1990 (100 %). La répartition détaillée en 2018 est la suivante : prairies (46 %), terres arables (38,5 %), zones agricoles hétérogènes (15,5 %).\\nL'IGN met par ailleurs à disposition un outil en ligne permettant de comparer l’évolution dans le temps de l’occupation des sols de la commune (ou de territoires à des échelles différentes). Plusieurs époques sont accessibles sous forme de cartes ou photos aériennes : la carte de Cassini (XVIIIe siècle), la carte d'état-major (1820-1866) et la période actuelle (1950 à aujourd'hui).\\n\\n\\nLe nom de la localité est attesté sous les formes Vasrouvilla (sans date), Warouvilla en 1280, Varrouvilla vers 1280.\\nLe toponyme est basé sur un anthroponyme germanique tel que Warald ou Warulfus,, (forme latinisée, comprendre Warulf/Warolf cf. Warulfe Ier d'Uxelles) et sur l'ancien français ville/vile dans son sens originel de « domaine rural » issu du latin villa rustica.\\nRemarque : le même nom de personne est attesté au moins une seconde fois en Normandie dans Montgaroult (Orne, Mons Warulfi 1063), cette commune se trouvant au sud de l'isoglosse w- / g(u)- (qui est parallèle à la ligne Joret en Normandie), d'où le passage de [w] > [g], alors que dans Varouville, il s'agit de l'évolution secondaire [w] > [v] qui s'est produite seulement à partir du XIIe siècle.\\nLe gentilé est Varouvillais.\\n\\n\\nEntre 1911 et 1950, la commune est traversée par le « Tue-Vaques », le chemin de fer entre Cherbourg et Barfleur, dont on peut encore voir l'ancienne gare à l'architecture du XXe siècle, près de l'église.\\n\\n\\n\\nLe conseil municipal est composé de onze membres dont le maire et deux adjoints.\\n\\n\\nL'évolution du nombre d'habitants est connue à travers les recensements de la population effectués dans la commune depuis 1793. À partir de 2006, les populations légales des communes sont publiées annuellement par l'Insee. Le recensement repose désormais sur une collecte d'information annuelle, concernant successivement tous les territoires communaux au cours d'une période de cinq ans. Pour les communes de moins de 10 000 habitants, une enquête de recensement portant sur toute la population est réalisée tous les cinq ans, les populations légales des années intermédiaires étant quant à elles estimées par interpolation ou extrapolation. Pour la commune, le premier recensement exhaustif entrant dans le cadre du nouveau dispositif a été réalisé en 2005.\\nEn 2020, la commune comptait 233 habitants, en diminution de 12,08 % par rapport à 2014 (Manche : −0,97 %, France hors Mayotte : +1,9 %).\\nVarouville a compté jusqu'à 519 habitants en 1806.\\n\\n\\n\\n\\n\\nÉglise Saint-Martin (XIIIe siècle) avec son clocher en bâtière bâti en 1710, dont le mobilier fut fortement endommagé pendant la Révolution. Elle abrite une sculpture charité Saint-Martin avec donateur en pierre calcaire de la fin du XVe classée au titre objet aux monuments historiques. Elle formait à l'origine tympan au-dessus de la porte d'entrée de l'église et fut déplacée à l'intérieur de la nef afin d'être mieux conservée. Le donateur sans tête est représenté en prière, avec probablement son épouse derrière lui, à gauche du groupe sculpté. .\\nChâteau de la Bréhoulle.\\nAncienne gare, près de l'église, de la ligne de chemin de fer de Cherbourg à Barfleur où s'arrêtait le « tue-vaques ».\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"flat_contents\"][df_train.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3002, 1011, 5578, 1011, 1041, 25394, 3366]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.encode(\"Saint-Pierre-Église\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"labels_ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "10\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "14\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(sum(train_dataset[i][\"labels_ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID du token [SEP]: 102\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "\n",
    "print(f\"ID du token [SEP]: {sep_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(len(train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
