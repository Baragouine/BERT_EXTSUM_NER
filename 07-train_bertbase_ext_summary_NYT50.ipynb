{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Bert for extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import statistics\n",
    "import os\n",
    "from utils.split_all_docs import split_all_docs\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.DataLoader import DataLoader\n",
    "from utils.preprocess_df import preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "  try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "      return True   # Jupyter notebook or qtconsole\n",
    "    elif shell == 'TerminalInteractiveShell':\n",
    "      return False  # Terminal running IPython\n",
    "    else:\n",
    "      return False  # Other type (?)\n",
    "  except NameError:\n",
    "    return False      # Probably standard Python interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse args if script mode\n",
    "parser = argparse.ArgumentParser(description='extractive summary and ner using bert')\n",
    "\n",
    "parser.add_argument('-is_graphic',type=int,default=1,choices=[0,1])\n",
    "parser.add_argument('-gpu_num',type=int,default=0)\n",
    "parser.add_argument('-batch_size',type=int,default=4)#32)\n",
    "parser.add_argument('-epochs',type=int,default=100)\n",
    "parser.add_argument('-dataset',type=str,default=\"data/nyt_corpus_LDC2008T19_50.json\")\n",
    "\n",
    "args = None\n",
    "\n",
    "if is_notebook():\n",
    "  args = parser.parse_args(\"\")\n",
    "else:\n",
    "  args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse:\n",
      "is_graphic: True\n",
      "cuda_num: 0\n",
      "epochs 100\n",
      "batch_size 4\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "is_graphic = args.is_graphic != 0\n",
    "cuda_num = args.gpu_num\n",
    "bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# hyper-parameters\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "learning_rate = 1e-3\n",
    "early_stopping = 3\n",
    "model_name = \"08-train_bertbase_ext_summary_NYT50\"\n",
    "sub_folder_name = \"model_name__{}__time__{}__lr__{}__batch_size__{}__cuda_num__{}__early_stopping__{}\".format(model_name, time(), learning_rate, batch_size, cuda_num, early_stopping)\n",
    "checkpoints_folder = \"./checkpoints/\" + sub_folder_name\n",
    "loss_sum_coef = 0.5\n",
    "loss_ner_coef = 0.5\n",
    "average_number_of_sentences_per_document = 3\n",
    "\n",
    "# print\n",
    "print(\"parse:\")\n",
    "print(\"is_graphic:\", is_graphic)\n",
    "print(\"cuda_num:\", cuda_num)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "  # Display the number of available GPUs\n",
    "  print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "  # Display the name of each GPU\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"MPS available.\")\n",
    "else:\n",
    "  print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:\" + str(cuda_num) \n",
    "elif torch.backends.mps.is_available():\n",
    "  dev = torch.device(\"mps\")\n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(l):\n",
    "  return sum(l) / len(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.dataset)\n",
    "df = shuffle(df, random_state=0)\n",
    "\n",
    "df_test = df.iloc[0:3452]\n",
    "df_val = df.iloc[3452:7452]\n",
    "df_train = df.iloc[7452:]#9452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats corpus\n",
    "\n",
    "if False:\n",
    "  len_articles = []\n",
    "\n",
    "  for idx in df.index:\n",
    "    txt = df[\"flat_contents\"][idx]\n",
    "    txt = sent_tokenize(txt)\n",
    "    txt = \" [SEP] \".join(txt)\n",
    "    txt = bert_tokenizer.encode(txt, add_special_tokens=False)\n",
    "    len_articles.append(len(txt))\n",
    "\n",
    "  print(\"max:\", max(len_articles), \", mediane:\", statistics.median(len_articles), \", avg:\", average(len_articles), \", std:\", statistics.stdev(len_articles))\n",
    "  # max: 184812 , mediane: 862.5 , avg: 2146.653203237274 , std: 4145.829631357804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>docs</th>\n",
       "      <th>summaries</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419141</th>\n",
       "      <td>data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...</td>\n",
       "      <td>\\n        The dim, dank bathroom was the scene...</td>\n",
       "      <td>\\n        Woman and her 16-year-old nephew are...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599153</th>\n",
       "      <td>data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...</td>\n",
       "      <td>\\n        As Iraqi investigators began searchi...</td>\n",
       "      <td>\\n        Iraq's Sunni Arab leaders accuse Shi...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    paths  \\\n",
       "419141  data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...   \n",
       "599153  data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...   \n",
       "\n",
       "                                                     docs  \\\n",
       "419141  \\n        The dim, dank bathroom was the scene...   \n",
       "599153  \\n        As Iraqi investigators began searchi...   \n",
       "\n",
       "                                                summaries  \\\n",
       "419141  \\n        Woman and her 16-year-old nephew are...   \n",
       "599153  \\n        Iraq's Sunni Arab leaders accuse Shi...   \n",
       "\n",
       "                                                   labels  \n",
       "419141  [1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "599153  [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_df(df=df_train, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)\n",
    "val_dataset = preprocess_df(df=df_val, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)\n",
    "test_dataset = preprocess_df(df=df_test, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prop=0.3)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertExtSUMNER(nn.Module):\n",
    "  def __init__(self, bert_layer, bert_tokenizer, dim_emb=768) -> None:\n",
    "    super(BertExtSUMNER, self).__init__()\n",
    "    self.bert_layer = bert_layer\n",
    "    self.bert_tokenizer = bert_tokenizer\n",
    "    self.dim_emb = dim_emb\n",
    "\n",
    "    # predict summary\n",
    "    self.w_sum = nn.Linear(dim_emb, 1)\n",
    "    \n",
    "    # NER\n",
    "    self.w_ner = nn.Linear(dim_emb, 1)\n",
    "\n",
    "  def forward(self, list_input_ids, list_attention_mask):\n",
    "    id_sep = bert_tokenizer.sep_token_id\n",
    "    id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in range(len(list_input_ids)):\n",
    "      input_ids.append(list_input_ids[i].to(self.bert_layer.device))\n",
    "      attention_mask.append(list_attention_mask[i].to(self.bert_layer.device))\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "\n",
    "    x = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    mask_sep = (input_ids == id_sep).view(-1)\n",
    "    mask_not_sep = (torch.ne(input_ids, bert_tokenizer.pad_token_id) & torch.ne(input_ids, bert_tokenizer.sep_token_id)).view(-1)\n",
    "    x = x.last_hidden_state\n",
    "    x = x.view(-1, x.size(-1))\n",
    "    emb_sent = x[mask_sep, :]\n",
    "    emb_entities = x[mask_not_sep, :]\n",
    "\n",
    "    o_sum = self.w_sum(emb_sent)\n",
    "    o_sum = torch.sigmoid(o_sum).squeeze(-1)\n",
    "\n",
    "    o_ner = self.w_ner(emb_entities)\n",
    "    o_ner = torch.sigmoid(o_ner).squeeze(-1)\n",
    "\n",
    "    return o_sum, o_ner\n",
    "\n",
    "  def save(self, fname):\n",
    "    torch.save(self.state_dict(), fname)\n",
    "\n",
    "  def load(self, fname):\n",
    "    self.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoints_folder):\n",
    "  os.makedirs(checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611584/1346601038.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"doc_splitted\"] = split_all_docs(df_val[\"docs\"])\n"
     ]
    }
   ],
   "source": [
    "df_val[\"doc_splitted\"] = split_all_docs(df_val[\"docs\"])\n",
    "val_set = df_val\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3221/3221 [46:16<00:00,  1.16batch/s, loss=0.697, loss_sum=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : val loss = 0.694, val loss summary = 0.694, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3221/3221 [46:42<00:00,  1.15batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : val loss = 0.701, val loss summary = 0.701, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3221/3221 [46:00<00:00,  1.17batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : val loss = 0.695, val loss summary = 0.695, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3221/3221 [46:57<00:00,  1.14batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : val loss = 0.693, val loss summary = 0.693, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3221/3221 [46:46<00:00,  1.15batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : val loss = 0.694, val loss summary = 0.694, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3221/3221 [46:55<00:00,  1.14batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : val loss = 0.694, val loss summary = 0.694, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3221/3221 [46:49<00:00,  1.15batch/s, loss=0.694, loss_sum=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : val loss = 0.694, val loss summary = 0.694, r1 = 0.389, r2 = 0.180, rL = 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3221/3221 [46:41<00:00,  1.15batch/s, loss=0.693, loss_sum=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : val loss = 0.695, val loss summary = 0.695, r1 = 0.389, r2 = 0.180, rL = 0.271\n",
      "Training duration = 24532.332835435867\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "arr_train_loss = []\n",
    "arr_train_loss_sum = []\n",
    "#arr_train_loss_ner = []\n",
    "#arr_train_acc_sum = []\n",
    "#arr_train_acc_ner = []\n",
    "arr_val_loss = []\n",
    "#arr_val_acc_sum = []\n",
    "#arr_val_acc_ner = []\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  # Train\n",
    "  model.train()\n",
    "  nb_batch_train = 0\n",
    "  nb_loss_train = 0\n",
    "  total_train_loss = 0\n",
    "  total_train_loss_sum = 0\n",
    "  #total_train_loss_ner = 0\n",
    "  #total_train_acc_sum = 0\n",
    "  #total_train_acc_ner = 0\n",
    "  \n",
    "  id_sep = bert_tokenizer.sep_token_id\n",
    "  id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "  for i in range(len(train_loader)):\n",
    "    train_loader[i]\n",
    "\n",
    "  with tqdm(train_loader, unit=\"batch\", total=len(train_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "      tepoch.set_description(f\"Epoch {epoch}\")\n",
    "      #if dev != \"cpu\":\n",
    "      #  torch.cuda.empty_cache()\n",
    "      list_input_ids = batch[\"input_ids\"]\n",
    "      list_attention_mask = batch[\"attention_mask\"]\n",
    "      list_targets_sum = batch[\"labels\"]\n",
    "      #list_targets_ner = batch[\"labels_ner\"]\n",
    "      \n",
    "      list_y_sum_pred = []\n",
    "      #list_y_ner_pred = []\n",
    "      for i in range(len(list_input_ids)):\n",
    "        y_sum_pred, y_ner_pred = model(list_input_ids[i:i+1], list_attention_mask[i:i+1])\n",
    "\n",
    "        loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[i], dtype=torch.float).to(device))\n",
    "        #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[i], dtype=torch.float).to(device))\n",
    "        \n",
    "        #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "        loss = loss_sum\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        nb_loss_train += 1\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_loss_sum += loss_sum.item()\n",
    "        #total_train_loss_ner += loss_ner.item()\n",
    "\n",
    "        list_y_sum_pred.append(y_sum_pred.detach())\n",
    "        #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "      nb_batch_train += 1\n",
    "\n",
    "      y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "      #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "      targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "      #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "      probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "      probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "      #total_train_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "      tepoch.set_postfix(loss=total_train_loss/nb_loss_train, loss_sum=total_train_loss_sum/nb_loss_train)\n",
    "\n",
    "  # Save model\n",
    "  model.save(checkpoints_folder + \"/\" + model_name + \"-\" + str(epoch) + \".pt\")\n",
    "\n",
    "  # Eval\n",
    "  model.eval()\n",
    "  nb_batch_val = 0\n",
    "  nb_loss_val = 0\n",
    "  total_val_loss = 0\n",
    "  total_val_loss_sum = 0\n",
    "  #total_val_loss_ner = 0\n",
    "  #total_val_acc_sum = 0\n",
    "  #total_val_acc_ner = 0\n",
    "  total_r1 = 0\n",
    "  total_r2 = 0\n",
    "  total_rl = 0\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  for i, batch in enumerate(val_loader):\n",
    "    #if dev != \"cpu\":\n",
    "    #  torch.cuda.empty_cache()\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "      \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      nb_loss_val += 1      \n",
    "      total_val_loss += loss.item()\n",
    "      total_val_loss_sum += loss_sum.item()\n",
    "      #total_val_loss_ner += loss_ner.item()\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    nb_batch_val += 1\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "    #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "    doc = val_set[\"doc_splitted\"].iloc[i]\n",
    "    summaries = val_set[\"summaries\"].iloc[i]\n",
    "\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    doc_lens = [len(doc)]\n",
    "    for j in range(doc_lens[0]):\n",
    "      txt = txt + \". \" + doc[indices[j]]\n",
    "      y_pred_thresh.append(indices[j])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for j in y_pred_thresh:\n",
    "      txt = txt + \". \" + doc[j]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    total_r1 += scores[\"rouge1\"].recall\n",
    "    total_r2 += scores[\"rouge2\"].recall\n",
    "    total_rl += scores[\"rougeL\"].recall\n",
    "\n",
    "    probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #total_val_acc_sum += accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=doc_lens, average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #total_val_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "  print(\"Epoch {} : val loss = {:.3f}, val loss summary = {:.3f}, r1 = {:.3f}, r2 = {:.3f}, rL = {:.3f}\".format(epoch, total_val_loss / nb_loss_val, total_val_loss_sum / nb_loss_val, total_r1 / nb_batch_val, total_r2 / nb_batch_val, total_rl / nb_batch_val))\n",
    "\n",
    "  if len(arr_val_loss) >= early_stopping+1:\n",
    "    if min(arr_val_loss[-early_stopping:]) >= arr_val_loss[-(early_stopping+1)]:\n",
    "      break\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  arr_train_loss.append(total_train_loss / nb_batch_train)\n",
    "  \n",
    "  #arr_train_acc_sum.append(total_train_acc_sum / nb_batch_train)\n",
    "  #arr_train_acc_ner.append(total_train_acc_ner / nb_batch_train)\n",
    "\n",
    "  arr_val_loss.append(total_val_loss / nb_batch_val)\n",
    "  #arr_val_acc_sum.append(total_val_acc_sum / nb_batch_val)\n",
    "  #arr_val_acc_ner.append(total_val_acc_ner / nb_batch_val)\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = {}\n",
    "training_metrics[\"duration\"]   = t2 - t1\n",
    "training_metrics[\"train_loss\"] = arr_train_loss\n",
    "#training_metrics[\"train_acc_sum\"]  = arr_train_acc_sum\n",
    "#training_metrics[\"train_acc_ner\"]  = arr_train_acc_ner\n",
    "training_metrics[\"val_loss\"]   = arr_val_loss\n",
    "#training_metrics[\"val_acc_sum\"]    = arr_val_acc_sum\n",
    "#training_metrics[\"val_acc_ner\"]    = arr_val_acc_ner\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/training_metrics.json\", 'w') as fp:\n",
    "  json.dump(training_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw Losses\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_loss) + 1)), arr_train_loss, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_loss) + 1)), arr_val_loss, label=\"val\")\n",
    "\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_sum) + 1)), arr_train_acc_sum, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_sum) + 1)), arr_val_acc_sum, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy Summary\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_ner) + 1)), arr_train_acc_ner, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_ner) + 1)), arr_val_acc_ner, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy NER\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch = np.argmin(np.array(arr_val_loss)) + 1\n",
    "model.load(checkpoints_folder + \"/\" + model_name + \"-\" + str(best_epoch) + \".pt\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611584/147892152.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"doc_splitted\"] = split_all_docs(df_test[\"docs\"], False)\n"
     ]
    }
   ],
   "source": [
    "df_test[\"doc_splitted\"] = split_all_docs(df_test[\"docs\"], False)\n",
    "test_set = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval model: 100%|██████████| 3452/3452 [03:56<00:00, 14.58batch/s, loss=0.693, loss_sum=0.693, rouge1=0.384, rouge2=0.177, rougeL=0.268]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "arr_loss = []\n",
    "arr_loss_sum = []\n",
    "#arr_loss_ner = []\n",
    "#accuracy_sum = []\n",
    "#accuracy_ner = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "counter = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "  for batch in tepoch:\n",
    "    tepoch.set_description(\"Eval model\")\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "    \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      arr_loss.append(loss.item())\n",
    "      arr_loss_sum.append(loss_sum.item())\n",
    "      #arr_loss_ner.append(loss_ner.item())\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    #targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "\n",
    "    doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "    summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "    probs = np.array(y_sum_pred.tolist()) # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #probs = threshold_probs_by_nb(probs=probs, doc_lens=[probs.shape[0]], average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #probs = threshold_probs_by_prop(probs=probs, doc_lens=[probs.shape[0]], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document)\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in range(min(len(doc), y_sum_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[indices[i]]\n",
    "      y_pred_thresh.append(indices[i])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in y_pred_thresh:#range(min(len(doc), y_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[i]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "    arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "    arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "    #accuracy_sum.append(accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=[len(probs)], average_number_of_sentences_per_document=average_number_of_sentences_per_document))\n",
    "    #accuracy.append(accuracy_prop_sent_per_doc_fn(probs=probs, targets=targets.cpu().detach().numpy(), doc_lens=[len(probs)], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document))\n",
    "    #accuracy_ner.append(torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0])\n",
    "\n",
    "    tepoch.set_postfix(loss=average(arr_loss), loss_sum=average(arr_loss_sum), rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "#test_metrics[\"accuracy_sum\"] = average(accuracy_sum)\n",
    "#test_metrics[\"accuracy_ner\"] = average(accuracy_ner)\n",
    "test_metrics[\"rouge1\"]   = average(arr_rouge1)\n",
    "test_metrics[\"rouge2\"]   = average(arr_rouge2)\n",
    "test_metrics[\"rougeL\"]   = average(arr_rougeL)\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/test_metrics.json\", 'w') as fp:\n",
    "  json.dump(test_metrics, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lead-3: 100%|██████████| 3452/3452 [00:14<00:00, 233.79batch/s, rouge1=0.401, rouge2=0.226, rougeL=0.308]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"Lead-3\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(min(len(doc), 3)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First n char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "First-n-char': 100%|██████████| 3452/3452 [00:17<00:00, 199.21batch/s, rouge1=0.462, rouge2=0.256, rougeL=0.347]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"First-n-char'\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(len(doc)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsaid/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Does not execute this cell if you want to execute the following cells.\n",
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(train_dataset[0][\"input_ids\"] == 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][\"labels_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2474, 5715, 9765, 8740, 13926, 1011, 9765, 4241, 17155, 16778, 2078, 1012, 102, 2365, 8945, 12514, 9765, 1037, 1016, 1010, 1019, 2463, 1037, 1048, 1005, 9765, 2139, 3002, 1011, 5578, 1011, 1041, 25394, 3366, 3802, 1037, 1022, 2463, 1037, 1048, 1005, 15068, 4355, 2139, 3347, 21031, 3126, 1012, 102, 3393, 18856, 9581, 2102, 21864, 14418, 21162, 5562, 2474, 5715, 9765, 24209, 11475, 8873, 2063, 1010, 4372, 2230, 1010, 2139, 1077, 18856, 9581, 2102, 4153, 7413, 23151, 2278, 1090, 1010, 7367, 7811, 2474, 5939, 18155, 8649, 2666, 4078, 18856, 9581, 3215, 2139, 2474, 2605, 21864, 4012, 13876, 2063, 2632, 5668, 17504, 2102, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 4372, 12609, 1010, 2474, 5715, 24501, 21748, 2102, 4241, 2828, 1077, 18856, 9581, 2102, 4153, 7413, 1090, 18033, 2474, 5579, 27859, 16558, 2666, 11968, 2777, 8780, 1011, 2605, 1010, 21864, 11265, 4012, 13876, 2063, 4078, 2953, 2863, 2483, 1010, 4372, 6765, 10439, 3217, 5403, 1010, 10861, 25022, 2078, 4160, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 8292, 2828, 2139, 18856, 9581, 2102, 7367, 19817, 4215, 14663, 11968, 4078, 7715, 2079, 18796, 2015, 3802, 16655, 20228, 2226, 25500, 11368, 7373, 5816, 3672, 11113, 29067, 10111, 1006, 4372, 14975, 13642, 2278, 4649, 2566, 20689, 23757, 2015, 2310, 16885, 2139, 1048, 1005, 2012, 5802, 28437, 1007, 1010, 16360, 8445, 2666, 2000, 4904, 8740, 2146, 2139, 1048, 1005, 4776, 2063, 13642, 2278, 4895, 26523, 4555, 1040, 1005, 13323, 16429, 2890, 1037, 10768, 19716, 3771, 1012, 102, 4649, 11498, 11368, 6072, 18856, 9581, 28437, 2015, 21864, 2006, 2102, 2566, 15630, 1040, 1521, 27859, 16558, 4313, 2474, 5939, 18155, 8649, 2666, 2139, 2230, 4012, 6442, 4765, 2416, 10857, 10364, 4649, 7715, 3802, 17504, 2102, 10364, 4649, 13511, 2015, 1010, 2123, 2102, 4649, 10380, 9236, 11370, 1037, 2474, 3671, 2063, 3411, 1011, 2456, 1012, 102, 4649, 17419, 4054, 2229, 10857, 14418, 21162, 29196, 2102, 2474, 5715, 2365, 2102, 2556, 10285, 18033, 1048, 1005, 4372, 3540, 16200, 25022, 1011, 19804, 2229, 1012, 102, 13642, 2278, 3393, 2689, 3672, 18856, 9581, 28437, 1010, 8292, 2015, 10857, 2006, 2102, 23408, 4747, 5657, 1012, 102, 16655, 3802, 12672, 19148, 2063, 4372, 2297, 11968, 2474, 3257, 2236, 2063, 2139, 1048, 1005, 4372, 2121, 11239, 3802, 4241, 18856, 9581, 2102, 3143, 2063, 11968, 4078, 25041, 3164, 2229, 3653, 6767, 4183, 4372, 1041, 16020, 2102, 10861, 2474, 4860, 9587, 20684, 2638, 16475, 14995, 2102, 13675, 28100, 2890, 3802, 2474, 20228, 2226, 25500, 11368, 7373, 9587, 20684, 2638, 21790, 18116, 1010, 13642, 2278, 2000, 10421, 14876, 2483, 2139, 24898, 2015, 8358, 3164, 2229, 1012, 102, 8292, 2015, 2689, 8163, 21877, 27346, 2102, 3802, 2890, 9530, 9153, 4570, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2139, 2777, 8780, 1011, 2605, 2474, 4606, 4013, 5403, 1010, 1077, 2175, 10087, 3077, 1090, 1010, 7505, 2474, 5715, 2139, 2175, 10087, 3077, 1011, 3393, 1996, 4014, 1010, 28616, 2063, 4372, 2326, 4372, 3851, 3802, 21864, 7367, 19817, 7140, 3726, 1037, 1023, 2463, 1037, 5285, 1040, 1005, 1051, 5562, 4887, 1010, 1010, 15068, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 9765, 2139, 2184, 1010, 1021, 6362, 3802, 2474, 18535, 3126, 2139, 13511, 2015, 2139, 6205, 2683, 1010, 1021, 3461, 10364, 2474, 2558, 2063, 3261, 1011, 2230, 1012, 102, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2010, 29469, 4226, 2474, 4606, 4013, 5403, 1010, 1077, 24188, 20431, 1516, 5003, 6279, 8743, 2271, 1090, 1010, 7505, 2474, 5715, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 28616, 2063, 4372, 2326, 4372, 4437, 3802, 1037, 2539, 2463, 1010, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 23408, 4747, 5657, 2139, 2184, 1010, 1018, 6362, 10364, 2474, 2558, 2063, 3411, 1011, 2456, 1037, 2184, 1010, 1021, 6362, 10364, 3261, 1011, 2230, 1010, 16405, 2483, 1037, 2340, 1010, 1015, 6362, 10364, 2889, 1011, 12609, 1012, 102, 13075, 7140, 3077, 9765, 16655, 5715, 3541, 2063, 1010, 2482, 15317, 26208, 2102, 2112, 2666, 4078, 16569, 21877, 2226, 15068, 24403, 21877, 2226, 9742, 2015, 1010, 8740, 12411, 2015, 2139, 2474, 26192, 15029, 2063, 2139, 7939, 28032, 2063, 2139, 1048, 1005, 16021, 4402, 1010, 1010, 1010, 1012, 102, 11968, 9932, 6216, 9236, 2474, 5715, 26208, 2102, 2112, 2666, 2139, 1048, 1005, 2250, 2063, 1040, 1005, 8432, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 2123, 2102, 15317, 9765, 16655, 5715, 2139, 2474, 2522, 21017, 2638, 1012, 102, 8292, 4674, 2250, 2063, 1010, 21864, 19723, 22107, 2063, 6255, 16569, 1010, 9765, 4937, 20265, 29346, 2063, 18033, 4649, 9149, 2139, 2753, 2199, 1037, 25175, 3619, 2139, 3263, 2199, 10427, 11390, 1010, 1012, 102, 1048, 1005, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1010, 2425, 2063, 24209, 1005, 15317, 24501, 21748, 2102, 2139, 2474, 2918, 2139, 2123, 24045, 2015, 2885, 24336, 1040, 1521, 6139, 16012, 21281, 5332, 4226, 4078, 14017, 2015, 2522, 11467, 2455, 3104, 1006, 18856, 2278, 1007, 1010, 9765, 9388, 4226, 2063, 11968, 1048, 1005, 5197, 4078, 26568, 3406, 7442, 2015, 12943, 7277, 29111, 1006, 2531, 1003, 4372, 2760, 1007, 1010, 16655, 10817, 8909, 4765, 7413, 1037, 3526, 2063, 2139, 2901, 1006, 2531, 1003, 1007, 1012, 102, 2474, 16360, 8445, 22753, 6987, 10559, 4372, 2760, 9765, 2474, 24086, 18941, 2063, 1024, 10996, 2015, 1006, 4805, 1003, 1007, 1010, 25170, 2015, 5424, 4244, 1006, 4229, 1010, 1019, 1003, 1007, 1010, 10019, 12943, 7277, 29111, 21770, 10624, 6914, 2229, 1006, 2321, 1010, 1019, 1003, 1007, 1012, 102, 1048, 1005, 16270, 2777, 11968, 9932, 6216, 9236, 1037, 22137, 4895, 2041, 4014, 4372, 5622, 10177, 2566, 11368, 5794, 2102, 2139, 12826, 2099, 1048, 1521, 6622, 18033, 3393, 29023, 2139, 1048, 1521, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1006, 15068, 2139, 26568, 3406, 7442, 2015, 1037, 4078, 14925, 18223, 2229, 2367, 2229, 1007, 1012, 102, 4606, 17301, 2869, 4958, 2080, 10997, 2365, 2102, 7801, 2015, 27411, 2433, 2063, 2139, 11122, 2229, 15068, 7760, 29347, 23144, 5267, 1024, 2474, 11122, 2063, 2139, 16220, 5498, 1006, 16855, 6137, 2063, 9033, 8586, 2571, 1007, 1010, 2474, 11122, 2063, 1040, 1005, 17997, 1011, 2350, 1006, 11102, 1011, 7647, 1007, 3802, 2474, 2558, 2063, 2552, 16284, 2571, 1006, 3925, 1037, 8740, 23099, 4103, 1005, 17504, 1007, 1012, 102, 3393, 2053, 2213, 2139, 2474, 2334, 4221, 9765, 2012, 22199, 2063, 27411, 4649]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nLa commune est au nord-est du Cotentin. Son bourg est à 2,5 km à l'est de Saint-Pierre-Église et à 8 km à l'ouest de Barfleur.\\n\\n\\nLe climat qui caractérise la commune est qualifié, en 2010, de « climat océanique franc », selon la typologie des climats de la France qui compte alors huit grands types de climats en métropole. En 2020, la commune ressort du type « climat océanique » dans la classification établie par Météo-France, qui ne compte désormais, en première approche, que cinq grands types de climats en métropole. Ce type de climat se traduit par des températures douces et une pluviométrie relativement abondante (en liaison avec les perturbations venant de l'Atlantique), répartie tout au long de l'année avec un léger maximum d'octobre à février.\\nLes paramètres climatiques qui ont permis d’établir la typologie de 2010 comportent six variables pour les températures et huit pour les précipitations, dont les valeurs correspondent à la normale 1971-2000. Les sept principales variables caractérisant la commune sont présentées dans l'encadré ci-après.\\n\\nAvec le changement climatique, ces variables ont évolué. Une étude réalisée en 2014 par la Direction générale de l'Énergie et du Climat complétée par des études régionales prévoit en effet que la température moyenne devrait croître et la pluviométrie moyenne baisser, avec toutefois de fortes variations régionales. Ces changements peuvent être constatés sur la station météorologique de Météo-France la plus proche, « Gonneville », sur la commune de Gonneville-Le Theil, mise en service en 1959 et qui se trouve à 9 km à vol d'oiseau,, où la température moyenne annuelle est de 10,7 °C et la hauteur de précipitations de 919,7 mm pour la période 1981-2010.\\nSur la station météorologique historique la plus proche, « Cherbourg – Maupertus », sur la commune de Cherbourg-en-Cotentin, mise en service en 1935 et à 19 km, la température moyenne annuelle évolue de 10,4 °C pour la période 1971-2000 à 10,7 °C pour 1981-2010, puis à 11,1 °C pour 1991-2020.\\n\\n\\n\\n\\nVarouville est une commune rurale, car elle fait partie des communes peu ou très peu denses, au sens de la grille communale de densité de l'Insee,,,.\\nPar ailleurs la commune fait partie de l'aire d'attraction de Cherbourg-en-Cotentin, dont elle est une commune de la couronne. Cette aire, qui regroupe 77 communes, est catégorisée dans les aires de 50 000 à moins de 200 000 habitants,.\\n\\n\\n\\nL'occupation des sols de la commune, telle qu'elle ressort de la base de données européenne d’occupation biophysique des sols Corine Land Cover (CLC), est marquée par l'importance des territoires agricoles (100 % en 2018), une proportion identique à celle de 1990 (100 %). La répartition détaillée en 2018 est la suivante : prairies (46 %), terres arables (38,5 %), zones agricoles hétérogènes (15,5 %).\\nL'IGN met par ailleurs à disposition un outil en ligne permettant de comparer l’évolution dans le temps de l’occupation des sols de la commune (ou de territoires à des échelles différentes). Plusieurs époques sont accessibles sous forme de cartes ou photos aériennes : la carte de Cassini (XVIIIe siècle), la carte d'état-major (1820-1866) et la période actuelle (1950 à aujourd'hui).\\n\\n\\nLe nom de la localité est attesté sous les formes Vasrouvilla (sans date), Warouvilla en 1280, Varrouvilla vers 1280.\\nLe toponyme est basé sur un anthroponyme germanique tel que Warald ou Warulfus,, (forme latinisée, comprendre Warulf/Warolf cf. Warulfe Ier d'Uxelles) et sur l'ancien français ville/vile dans son sens originel de « domaine rural » issu du latin villa rustica.\\nRemarque : le même nom de personne est attesté au moins une seconde fois en Normandie dans Montgaroult (Orne, Mons Warulfi 1063), cette commune se trouvant au sud de l'isoglosse w- / g(u)- (qui est parallèle à la ligne Joret en Normandie), d'où le passage de [w] > [g], alors que dans Varouville, il s'agit de l'évolution secondaire [w] > [v] qui s'est produite seulement à partir du XIIe siècle.\\nLe gentilé est Varouvillais.\\n\\n\\nEntre 1911 et 1950, la commune est traversée par le « Tue-Vaques », le chemin de fer entre Cherbourg et Barfleur, dont on peut encore voir l'ancienne gare à l'architecture du XXe siècle, près de l'église.\\n\\n\\n\\nLe conseil municipal est composé de onze membres dont le maire et deux adjoints.\\n\\n\\nL'évolution du nombre d'habitants est connue à travers les recensements de la population effectués dans la commune depuis 1793. À partir de 2006, les populations légales des communes sont publiées annuellement par l'Insee. Le recensement repose désormais sur une collecte d'information annuelle, concernant successivement tous les territoires communaux au cours d'une période de cinq ans. Pour les communes de moins de 10 000 habitants, une enquête de recensement portant sur toute la population est réalisée tous les cinq ans, les populations légales des années intermédiaires étant quant à elles estimées par interpolation ou extrapolation. Pour la commune, le premier recensement exhaustif entrant dans le cadre du nouveau dispositif a été réalisé en 2005.\\nEn 2020, la commune comptait 233 habitants, en diminution de 12,08 % par rapport à 2014 (Manche : −0,97 %, France hors Mayotte : +1,9 %).\\nVarouville a compté jusqu'à 519 habitants en 1806.\\n\\n\\n\\n\\n\\nÉglise Saint-Martin (XIIIe siècle) avec son clocher en bâtière bâti en 1710, dont le mobilier fut fortement endommagé pendant la Révolution. Elle abrite une sculpture charité Saint-Martin avec donateur en pierre calcaire de la fin du XVe classée au titre objet aux monuments historiques. Elle formait à l'origine tympan au-dessus de la porte d'entrée de l'église et fut déplacée à l'intérieur de la nef afin d'être mieux conservée. Le donateur sans tête est représenté en prière, avec probablement son épouse derrière lui, à gauche du groupe sculpté. .\\nChâteau de la Bréhoulle.\\nAncienne gare, près de l'église, de la ligne de chemin de fer de Cherbourg à Barfleur où s'arrêtait le « tue-vaques ».\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"flat_contents\"][df_train.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3002, 1011, 5578, 1011, 1041, 25394, 3366]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.encode(\"Saint-Pierre-Église\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"labels_ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "10\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "14\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(sum(train_dataset[i][\"labels_ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID du token [SEP]: 102\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "\n",
    "print(f\"ID du token [SEP]: {sep_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(len(train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
