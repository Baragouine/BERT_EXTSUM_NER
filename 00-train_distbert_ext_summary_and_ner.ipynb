{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Bert for extractive summarization and NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsaid/anaconda3/envs/stage/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import statistics\n",
    "import os\n",
    "from utils.split_all_docs import split_all_docs\n",
    "from utils.accuracy_nb_sent_per_doc import accuracy_nb_sent_per_doc_fn\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "#from utils.DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "  try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "      return True   # Jupyter notebook or qtconsole\n",
    "    elif shell == 'TerminalInteractiveShell':\n",
    "      return False  # Terminal running IPython\n",
    "    else:\n",
    "      return False  # Other type (?)\n",
    "  except NameError:\n",
    "    return False      # Probably standard Python interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse args if script mode\n",
    "parser = argparse.ArgumentParser(description='extractive summary and ner using bert')\n",
    "\n",
    "parser.add_argument('-is_graphic',type=int,default=1,choices=[0,1])\n",
    "parser.add_argument('-gpu_num',type=int,default=0)\n",
    "parser.add_argument('-batch_size',type=int,default=32)\n",
    "parser.add_argument('-epochs',type=int,default=100)\n",
    "parser.add_argument('-dataset',type=str,default=\"data/wiki_geo_preprocessed.json\")\n",
    "parser.add_argument('-doc_column_name',type=str,default=\"flat_contents\")\n",
    "parser.add_argument('-labels_sum_column_name',type=str,default=\"labels_sentences\")\n",
    "parser.add_argument('-labels_ner_column_name',type=str,default=\"labels_entities\")\n",
    "\n",
    "args = None\n",
    "\n",
    "if is_notebook():\n",
    "  args = parser.parse_args(\"\")\n",
    "else:\n",
    "  args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse:\n",
      "is_graphic: True\n",
      "cuda_num: 0\n",
      "epochs 100\n",
      "batch_size 32\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "is_graphic = args.is_graphic != 0\n",
    "cuda_num = args.gpu_num\n",
    "bert_layer = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "padding_trunc_doc=512\n",
    "\n",
    "# hyper-parameters\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "learning_rate = 5e-4\n",
    "early_stopping = 3\n",
    "model_name = \"DistBERT_ExtSUM_NER\"\n",
    "sub_folder_name = \"model_name__{}__time__{}__lr__{}__batch_size__{}__cuda_num__{}__early_stopping__{}\".format(model_name, time(), learning_rate, batch_size, cuda_num, early_stopping)\n",
    "checkpoints_folder = \"./checkpoints/\" + sub_folder_name\n",
    "loss_sum_coef = 0.5\n",
    "loss_ner_coef = 0.5\n",
    "average_number_of_sentences_per_document = 3\n",
    "\n",
    "# print\n",
    "print(\"parse:\")\n",
    "print(\"is_graphic:\", is_graphic)\n",
    "print(\"cuda_num:\", cuda_num)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available.\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "  # Display the number of available GPUs\n",
    "  print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "  # Display the name of each GPU\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"MPS available.\")\n",
    "else:\n",
    "  print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:\" + str(cuda_num) \n",
    "elif torch.backends.mps.is_available():\n",
    "  dev = torch.device(\"mps\")\n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(l):\n",
    "  return sum(l) / len(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.dataset)\n",
    "df = shuffle(df, random_state=0)\n",
    "\n",
    "df_test = df.iloc[0:100]\n",
    "df_val = df.iloc[100:200]\n",
    "df_train = df.iloc[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats corpus\n",
    "\n",
    "if False:\n",
    "  len_articles = []\n",
    "\n",
    "  for idx in df.index:\n",
    "    txt = df[\"flat_contents\"][idx]\n",
    "    txt = sent_tokenize(txt)\n",
    "    txt = \" [SEP] \".join(txt)\n",
    "    txt = bert_tokenizer.encode(txt, add_special_tokens=False)\n",
    "    len_articles.append(len(txt))\n",
    "\n",
    "  print(\"max:\", max(len_articles), \", mediane:\", statistics.median(len_articles), \", avg:\", average(len_articles), \", std:\", statistics.stdev(len_articles))\n",
    "  # max: 184812 , mediane: 862.5 , avg: 2146.653203237274 , std: 4145.829631357804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>contents</th>\n",
       "      <th>entities</th>\n",
       "      <th>flat_contents</th>\n",
       "      <th>trunc_contents</th>\n",
       "      <th>labels_entities</th>\n",
       "      <th>labels_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>géologie</td>\n",
       "      <td>Sismicité au Japon</td>\n",
       "      <td>La sismicité au Japon est particulièrement imp...</td>\n",
       "      <td>La sismicité au Japon est particulièrement imp...</td>\n",
       "      <td>[10 septembre, 11 mars, 12 janvier, 1399, 1400...</td>\n",
       "      <td>\\n\\n\\n\\nLe Japon est un archipel volcanique, s...</td>\n",
       "      <td>\\n\\n\\n== Plaques et fosses ==\\n\\nLe Japon est ...</td>\n",
       "      <td>[[0, E, 0, 0, E, 0, 0, 0, 0, 0, L, C, C, R, C,...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>géographie générale</td>\n",
       "      <td>Voyage d'études</td>\n",
       "      <td>Voyage d'études est un roman inachevé de l'écr...</td>\n",
       "      <td>Voyage d'études est un roman inachevé de l'écr...</td>\n",
       "      <td>[1905 en littérature, 1991 en littérature, Abe...</td>\n",
       "      <td>\\n\\n\\n\\nEn 1903, Théophile Cart prononce un di...</td>\n",
       "      <td>\\n\\n\\n== Historique ==\\n\\nEn 1903, Théophile C...</td>\n",
       "      <td>[[0, 0, R, C, 0, 0, 0, 0, E, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                categories              titles  \\\n",
       "21430             géologie  Sismicité au Japon   \n",
       "7651   géographie générale     Voyage d'études   \n",
       "\n",
       "                                               summaries  \\\n",
       "21430  La sismicité au Japon est particulièrement imp...   \n",
       "7651   Voyage d'études est un roman inachevé de l'écr...   \n",
       "\n",
       "                                                contents  \\\n",
       "21430  La sismicité au Japon est particulièrement imp...   \n",
       "7651   Voyage d'études est un roman inachevé de l'écr...   \n",
       "\n",
       "                                                entities  \\\n",
       "21430  [10 septembre, 11 mars, 12 janvier, 1399, 1400...   \n",
       "7651   [1905 en littérature, 1991 en littérature, Abe...   \n",
       "\n",
       "                                           flat_contents  \\\n",
       "21430  \\n\\n\\n\\nLe Japon est un archipel volcanique, s...   \n",
       "7651   \\n\\n\\n\\nEn 1903, Théophile Cart prononce un di...   \n",
       "\n",
       "                                          trunc_contents  \\\n",
       "21430  \\n\\n\\n== Plaques et fosses ==\\n\\nLe Japon est ...   \n",
       "7651   \\n\\n\\n== Historique ==\\n\\nEn 1903, Théophile C...   \n",
       "\n",
       "                                         labels_entities  \\\n",
       "21430  [[0, E, 0, 0, E, 0, 0, 0, 0, 0, L, C, C, R, C,...   \n",
       "7651   [[0, 0, R, C, 0, 0, 0, 0, E, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                        labels_sentences  \n",
       "21430  [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...  \n",
       "7651   [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs:\n",
    "# * preprocessing 1 : https://towardsdatascience.com/nlp-preprocessing-with-nltk-3c04ee00edc0\n",
    "# * preprocessing 2 : https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "# Run the below line only the first time of running nltk\n",
    "# nltk.download()\n",
    "\n",
    "def preprocess_text(text, sent_tokenizer, bert_tokenizer, padding_trunc_doc, entities=None):\n",
    "  # tokenize sentence\n",
    "  text = sent_tokenizer(text)\n",
    "\n",
    "  # Add [SEP]\n",
    "  text = \" [SEP] \".join(text)\n",
    "\n",
    "  # tokenize with bert tokenizer\n",
    "  inputs = bert_tokenizer.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=False,\n",
    "    padding=\"max_length\",\n",
    "    max_length=padding_trunc_doc,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True\n",
    "  )\n",
    "\n",
    "  input_ids = inputs['input_ids'].squeeze()\n",
    "  attention_mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "  for i in range(input_ids.shape[0] - 1, -1, -1):\n",
    "    if input_ids[i] != bert_tokenizer.pad_token:\n",
    "      input_ids[i] = bert_tokenizer.sep_token_id\n",
    "      break\n",
    "\n",
    "  # Compute NER labels\n",
    "  if entities is not None:\n",
    "    linput_ids = input_ids.tolist()\n",
    "    labels_entities = [0 for _ in range(input_ids.shape[0])]\n",
    "    entities = sorted(entities, key=len, reverse=True)\n",
    "    for entity in entities:\n",
    "      entity_ids = bert_tokenizer.encode(entity, add_special_tokens=False)\n",
    "      zeros = [0 for _ in entity_ids]\n",
    "      for x, id in enumerate(linput_ids):\n",
    "        if len(entity_ids) == len(linput_ids[x:x+len(entity_ids)]) and entity_ids == linput_ids[x:x+len(entity_ids)] and labels_entities[x:x+len(entity_ids)] == zeros:\n",
    "          if len(entity_ids) >= 2:\n",
    "            for i in range(len(entity_ids)):\n",
    "              labels_entities[x+i] = 1#'C'\n",
    "            labels_entities[x] = 1#'L'\n",
    "            labels_entities[x+len(entity_ids) - 2] = 1#'R'\n",
    "          else:\n",
    "            labels_entities[x] = 1#'E'\n",
    "\n",
    "    return input_ids, attention_mask, labels_entities\n",
    "  \n",
    "  return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import LineTokenizer, sent_tokenize\n",
    "import torch\n",
    "\n",
    "# preprocess df\n",
    "def preprocess_df(df, bert_tokenizer, padding_trunc_doc, doc_column_name=\"docs\", labels_sum_column_name=\"labels_sum\", entities_column_name=None, is_sep_n=False):\n",
    "  nltk_line_tokenizer = LineTokenizer()\n",
    "  sent_tokenizer = None\n",
    "\n",
    "  if is_sep_n:\n",
    "    sent_tokenizer = lambda x: nltk_line_tokenizer.tokenize(x)\n",
    "  else:\n",
    "    sent_tokenizer = sent_tokenize\n",
    "\n",
    "  result = []\n",
    "  for idx in df.index:\n",
    "    if entities_column_name is not None:\n",
    "      input_ids, attention_mask, labels_entities = preprocess_text(df[doc_column_name][idx], sent_tokenizer=sent_tokenizer, bert_tokenizer=bert_tokenizer, padding_trunc_doc=padding_trunc_doc, entities=entities_column_name)\n",
    "      nb_sent = torch.sum(input_ids == bert_tokenizer.sep_token_id).item()\n",
    "      result.append({\"idx\" : idx, \"input_ids\" : input_ids, \"attention_mask\": attention_mask, \"labels_sum\" : df[labels_sum_column_name][idx][:nb_sent], \"labels_ner\" : labels_entities[:input_ids.shape[0]]})\n",
    "    else:\n",
    "      input_ids, attention_mask = preprocess_text(df[doc_column_name][idx], sent_tokenizer=sent_tokenizer, bert_tokenizer=bert_tokenizer, padding_trunc_doc=padding_trunc_doc)\n",
    "      nb_sent = torch.sum(input_ids == bert_tokenizer.sep_token_id).item()\n",
    "      result.append({\"idx\" : idx, \"input_ids\" : input_ids, \"attention_mask\": attention_mask, \"labels\" : df[labels_sum_column_name][idx][:nb_sent]})\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, ner=False):\n",
    "        assert batch_size > 0\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lidx = list(range(len(self.dataset)))\n",
    "        self.ner = ner\n",
    "\n",
    "        # Padding last batch if necessary\n",
    "        if len(self.lidx) % self.batch_size != 0:\n",
    "            self.lidx = self.lidx + random.sample(self.lidx, self.batch_size - (len(self.lidx) % self.batch_size))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.lidx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx >= 0\n",
    "        if idx == 0:\n",
    "            self.lidx = list(range(len(self.dataset)))\n",
    "\n",
    "            # Padding last batch if necessary\n",
    "            if len(self.lidx) % self.batch_size != 0:\n",
    "                self.lidx = self.lidx + random.sample(self.lidx, self.batch_size - (len(self.lidx) % self.batch_size))\n",
    "\n",
    "            # Shuffle if necessary\n",
    "            if self.shuffle:\n",
    "                random.shuffle(self.lidx)\n",
    "        if (idx >= len(self.lidx) / self.batch_size):\n",
    "            return self.dataset[len(self.dataset)]\n",
    "        idxs = self.lidx[idx*self.batch_size:idx*self.batch_size+self.batch_size]\n",
    "        batch = [self.dataset[i] for i in idxs]\n",
    "\n",
    "        batch = self.merge(batch)\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.lidx) / self.batch_size)\n",
    "\n",
    "    def merge(self, batch):\n",
    "        def merge_list(l):\n",
    "            res = []\n",
    "            for e in l:\n",
    "                res = res + e\n",
    "            return res\n",
    "\n",
    "        idxs = [e[\"idx\"] for e in batch]\n",
    "        input_ids = torch.cat([e[\"input_ids\"].unsqueeze(0) for e in batch], dim=0)\n",
    "        attention_mask = torch.cat([e[\"attention_mask\"].unsqueeze(0) for e in batch])\n",
    "        labels_sum = merge_list([e[\"labels_sum\"] for e in batch])\n",
    "        labels_ner = merge_list([e[\"labels_ner\"] for e in batch])\n",
    "        return {\"idx\" : idxs, \"input_ids\" : input_ids, \"attention_mask\": attention_mask, \"labels_sum\" : labels_sum, \"labels_ner\" : labels_ner}\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_df(df=df_train, bert_tokenizer=bert_tokenizer, padding_trunc_doc=padding_trunc_doc, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)\n",
    "val_dataset = preprocess_df(df=df_val, bert_tokenizer=bert_tokenizer, padding_trunc_doc=padding_trunc_doc, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)\n",
    "test_dataset = preprocess_df(df=df_test, bert_tokenizer=bert_tokenizer, padding_trunc_doc=padding_trunc_doc, doc_column_name=\"flat_contents\", labels_sum_column_name=\"labels_sentences\", entities_column_name=\"entities\", is_sep_n=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertExtSUMNER(nn.Module):\n",
    "  def __init__(self, bert_layer, bert_tokenizer, dim_emb=768) -> None:\n",
    "    super(BertExtSUMNER, self).__init__()\n",
    "    self.bert_layer = bert_layer\n",
    "    self.bert_tokenizer = bert_tokenizer\n",
    "    self.dim_emb = dim_emb\n",
    "\n",
    "    # predict summary\n",
    "    self.w_sum = nn.Linear(dim_emb, 1)\n",
    "    \n",
    "    # NER\n",
    "    self.w_ner = nn.Linear(dim_emb, 1)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    x = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    id_sep = bert_tokenizer.sep_token_id\n",
    "    id_pad = bert_tokenizer.pad_token\n",
    "    mask_sep = (input_ids == id_sep).view(-1)\n",
    "    mask_not_sep = ((input_ids != id_sep) & (input_ids != id_pad)).view(-1)\n",
    "    x = x.last_hidden_state\n",
    "    print(x.shape)\n",
    "    x = x.view(-1, self.dim_emb)\n",
    "    print(x.shape)\n",
    "    print(mask_sep.shape)\n",
    "    emb_sent = x[mask_sep, :]\n",
    "    emb_entities = x[mask_not_sep, :]\n",
    "\n",
    "    o_sum = self.w_sum(emb_sent)\n",
    "    o_sum = torch.sigmoid(o_sum).squeeze(-1)\n",
    "\n",
    "    o_ner = self.w_ner(emb_entities)\n",
    "    o_ner = torch.sigmoid(o_ner).squeeze(-1)\n",
    "\n",
    "    return o_sum, o_ner\n",
    "\n",
    "  def save(self, fname):\n",
    "    torch.save(self.state_dict(), fname)\n",
    "\n",
    "  def load(self, fname):\n",
    "    self.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoints_folder):\n",
    "  os.makedirs(checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/11/vkcttg8s2l55z1_vm9gcgq_c0000gn/T/ipykernel_1535/2083174348.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"doc_splitted\"] = split_all_docs(df_val[args.doc_column_name])\n"
     ]
    }
   ],
   "source": [
    "df_val[\"doc_splitted\"] = split_all_docs(df_val[args.doc_column_name])\n",
    "val_set = df_val\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([260]) torch.Size([260])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▌       | 1/4 [00:02<00:07,  2.59s/batch, accuracy_ner=0.528, accuracy_sum=0.531, loss=0.697, loss_ner=0.701, loss_sum=0.693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([257]) torch.Size([257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 2/4 [00:04<00:04,  2.34s/batch, accuracy_ner=0.763, accuracy_sum=0.474, loss=0.521, loss_ner=0.359, loss_sum=0.684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([317]) torch.Size([317])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▌  | 3/4 [00:07<00:02,  2.33s/batch, accuracy_ner=0.841, accuracy_sum=0.503, loss=0.539, loss_ner=0.246, loss_sum=0.831]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([288]) torch.Size([288])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [00:09<00:00,  2.38s/batch, accuracy_ner=0.88, accuracy_sum=0.48, loss=0.546, loss_ner=0.192, loss_sum=0.901]  \n",
      "/var/folders/11/vkcttg8s2l55z1_vm9gcgq_c0000gn/T/ipykernel_1535/3167211485.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(batch[\"attention_mask\"], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "Epoch 1 : val loss = 0.361, val loss summary = 0.693, val loss ner = 0.028, val accuracy summary = 0.518, val accuracy ner = 0.997, r1 = 0.239, r2 = 0.053, rL = 0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([303]) torch.Size([303])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  25%|██▌       | 1/4 [00:02<00:06,  2.18s/batch, accuracy_ner=0.997, accuracy_sum=0.439, loss=0.36, loss_ner=0.0319, loss_sum=0.688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([256]) torch.Size([256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 2/4 [00:04<00:04,  2.31s/batch, accuracy_ner=0.997, accuracy_sum=0.469, loss=0.371, loss_ner=0.0267, loss_sum=0.716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([289]) torch.Size([289])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  75%|███████▌  | 3/4 [00:06<00:02,  2.31s/batch, accuracy_ner=0.997, accuracy_sum=0.488, loss=0.367, loss_ner=0.0244, loss_sum=0.71] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([269]) torch.Size([269])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:09<00:00,  2.31s/batch, accuracy_ner=0.997, accuracy_sum=0.491, loss=0.364, loss_ner=0.022, loss_sum=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "Epoch 2 : val loss = 0.358, val loss summary = 0.696, val loss ner = 0.020, val accuracy summary = 0.584, val accuracy ner = 0.997, r1 = 0.259, r2 = 0.067, rL = 0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([286]) torch.Size([286])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  25%|██▌       | 1/4 [00:02<00:06,  2.24s/batch, accuracy_ner=0.997, accuracy_sum=0.441, loss=0.351, loss_ner=0.0212, loss_sum=0.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([300]) torch.Size([300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 2/4 [00:04<00:04,  2.37s/batch, accuracy_ner=0.997, accuracy_sum=0.507, loss=0.373, loss_ner=0.0228, loss_sum=0.723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([284]) torch.Size([284])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  75%|███████▌  | 3/4 [00:07<00:02,  2.36s/batch, accuracy_ner=0.997, accuracy_sum=0.501, loss=0.371, loss_ner=0.0222, loss_sum=0.72] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([261]) torch.Size([261])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:09<00:00,  2.36s/batch, accuracy_ner=0.997, accuracy_sum=0.498, loss=0.368, loss_ner=0.0217, loss_sum=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "Epoch 3 : val loss = 0.354, val loss summary = 0.687, val loss ner = 0.020, val accuracy summary = 0.494, val accuracy ner = 0.997, r1 = 0.235, r2 = 0.056, rL = 0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([293]) torch.Size([293])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  25%|██▌       | 1/4 [00:02<00:07,  2.55s/batch, accuracy_ner=0.996, accuracy_sum=0.457, loss=0.357, loss_ner=0.0269, loss_sum=0.688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([297]) torch.Size([297])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|█████     | 2/4 [00:04<00:04,  2.46s/batch, accuracy_ner=0.996, accuracy_sum=0.505, loss=0.366, loss_ner=0.0237, loss_sum=0.708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([274]) torch.Size([274])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  75%|███████▌  | 3/4 [00:07<00:02,  2.41s/batch, accuracy_ner=0.997, accuracy_sum=0.51, loss=0.362, loss_ner=0.0214, loss_sum=0.703] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([257]) torch.Size([257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:09<00:00,  2.35s/batch, accuracy_ner=0.997, accuracy_sum=0.502, loss=0.361, loss_ner=0.0203, loss_sum=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([512])\n",
      "Epoch 4 : val loss = 0.359, val loss summary = 0.699, val loss ner = 0.020, val accuracy summary = 0.519, val accuracy ner = 0.997, r1 = 0.239, r2 = 0.054, rL = 0.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([318]) torch.Size([318])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  25%|██▌       | 1/4 [00:02<00:07,  2.49s/batch, accuracy_ner=0.997, accuracy_sum=0.519, loss=0.357, loss_ner=0.0204, loss_sum=0.694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([275]) torch.Size([275])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|█████     | 2/4 [00:04<00:04,  2.41s/batch, accuracy_ner=0.997, accuracy_sum=0.492, loss=0.359, loss_ner=0.0205, loss_sum=0.697]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([32, 512, 768])\n",
      "torch.Size([16384, 768])\n",
      "torch.Size([16384])\n",
      "torch.Size([263]) torch.Size([263])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "arr_train_loss = []\n",
    "arr_train_loss_sum = []\n",
    "arr_train_loss_ner = []\n",
    "arr_train_acc_sum = []\n",
    "arr_train_acc_ner = []\n",
    "arr_val_loss = []\n",
    "arr_val_acc_sum = []\n",
    "arr_val_acc_ner = []\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  # Train\n",
    "  model.train()\n",
    "  nb_batch_train = 0\n",
    "  total_train_loss = 0\n",
    "  total_train_loss_sum = 0\n",
    "  total_train_loss_ner = 0\n",
    "  total_train_acc_sum = 0\n",
    "  total_train_acc_ner = 0\n",
    "  \n",
    "  id_sep = bert_tokenizer.sep_token_id\n",
    "  id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "  with tqdm(train_loader, unit=\"batch\", total=len(train_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "      tepoch.set_description(f\"Epoch {epoch}\")\n",
    "      #if dev != \"cpu\":\n",
    "      #  torch.cuda.empty_cache()\n",
    "      input_ids = batch[\"input_ids\"].to(device)\n",
    "      attention_mask = batch[\"attention_mask\"].to(device)\n",
    "      targets_sum = torch.tensor(batch[\"labels_sum\"], dtype=torch.float).to(device)\n",
    "      targets_ner = torch.tensor(batch[\"labels_ner\"], dtype=torch.float).to(device)[(input_ids.view(-1) != id_sep) & (input_ids.view(-1) != id_pad)]\n",
    "      \n",
    "      y_sum_pred, y_ner_pred = model(input_ids, attention_mask)\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, targets_sum)\n",
    "      loss_ner = criterion(y_ner_pred, targets_ner)\n",
    "      \n",
    "      loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "      nb_batch_train += 1\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_loss_sum += loss_sum.item()\n",
    "      total_train_loss_ner += loss_ner.item()\n",
    "\n",
    "      probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "      probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "      doc_lens = torch.sum(input_ids == id_sep, dim=1).tolist()\n",
    "      total_train_acc_sum += accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=doc_lens, average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "      total_train_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "      tepoch.set_postfix(loss=total_train_loss/nb_batch_train, loss_sum=total_train_loss_sum/nb_batch_train, loss_ner=total_train_loss_ner/nb_batch_train, accuracy_sum=total_train_acc_sum/nb_batch_train, accuracy_ner=total_train_acc_ner/nb_batch_train)\n",
    "\n",
    "  # Save model\n",
    "  model.save(checkpoints_folder + \"/\" + model_name + \"-\" + str(epoch) + \".pt\")\n",
    "\n",
    "  # Eval\n",
    "  model.eval()\n",
    "  nb_batch_val = 0\n",
    "  total_val_loss = 0\n",
    "  total_val_loss_sum = 0\n",
    "  total_val_loss_ner = 0\n",
    "  total_val_acc_sum = 0\n",
    "  total_val_acc_ner = 0\n",
    "  total_r1 = 0\n",
    "  total_r2 = 0\n",
    "  total_rl = 0\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del loss_ner\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  for i, batch in enumerate(val_loader):\n",
    "    #if dev != \"cpu\":\n",
    "    #  torch.cuda.empty_cache()\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"], dtype=torch.long).to(device)\n",
    "    targets_sum = torch.tensor(batch[\"labels_sum\"], dtype=torch.float).to(device)\n",
    "    targets_ner = torch.tensor(batch[\"labels_ner\"], dtype=torch.float).to(device)[(input_ids.view(-1) != id_sep) & (input_ids.view(-1) != id_pad)]\n",
    "\n",
    "    y_sum_pred, y_ner_pred = model(input_ids, attention_mask)\n",
    "\n",
    "    loss_sum = criterion(y_sum_pred, targets_sum)\n",
    "    loss_ner = criterion(y_ner_pred, targets_ner)\n",
    "    \n",
    "    loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "\n",
    "    nb_batch_val += 1\n",
    "    total_val_loss += loss.item()\n",
    "    total_val_loss_sum += loss_sum.item()\n",
    "    total_val_loss_ner += loss_ner.item()\n",
    "\n",
    "    doc = val_set[\"doc_splitted\"].iloc[i]\n",
    "    summaries = val_set[\"summaries\"].iloc[i]\n",
    "\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    doc_lens = torch.sum(input_ids == id_sep, dim=1).tolist()\n",
    "    for j in range(doc_lens[0]):\n",
    "      txt = txt + \". \" + doc[indices[j]]\n",
    "      y_pred_thresh.append(indices[j])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for j in y_pred_thresh:\n",
    "      txt = txt + \". \" + doc[j]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    total_r1 += scores[\"rouge1\"].recall\n",
    "    total_r2 += scores[\"rouge2\"].recall\n",
    "    total_rl += scores[\"rougeL\"].recall\n",
    "\n",
    "    probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    total_val_acc_sum += accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=doc_lens, average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    total_val_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "  print(\"Epoch {} : val loss = {:.3f}, val loss summary = {:.3f}, val loss ner = {:.3f}, val accuracy summary = {:.3f}, val accuracy ner = {:.3f}, r1 = {:.3f}, r2 = {:.3f}, rL = {:.3f}\".format(epoch, total_val_loss / nb_batch_val, total_val_loss_sum / nb_batch_val, total_val_loss_ner / nb_batch_val, total_val_acc_sum / nb_batch_val, total_val_acc_ner / nb_batch_val, total_r1 / nb_batch_val, total_r2 / nb_batch_val, total_rl / nb_batch_val))\n",
    "\n",
    "  if len(arr_val_loss) >= early_stopping+1:\n",
    "    if min(arr_val_loss[-early_stopping:]) >= arr_val_loss[-(early_stopping+1)]:\n",
    "      break\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del loss_ner\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  arr_train_loss.append(total_train_loss / nb_batch_train)\n",
    "  \n",
    "  arr_train_acc_sum.append(total_train_acc_sum / nb_batch_train)\n",
    "  arr_train_acc_ner.append(total_train_acc_ner / nb_batch_train)\n",
    "\n",
    "  arr_val_loss.append(total_val_loss / nb_batch_val)\n",
    "  arr_val_acc_sum.append(total_val_acc_sum / nb_batch_val)\n",
    "  arr_val_acc_ner.append(total_val_acc_ner / nb_batch_val)\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = {}\n",
    "training_metrics[\"duration\"]   = t2 - t1\n",
    "training_metrics[\"train_loss\"] = arr_train_loss\n",
    "training_metrics[\"train_acc_sum\"]  = arr_train_acc_sum\n",
    "training_metrics[\"train_acc_ner\"]  = arr_train_acc_ner\n",
    "training_metrics[\"val_loss\"]   = arr_val_loss\n",
    "training_metrics[\"val_acc_sum\"]    = arr_val_acc_sum\n",
    "training_metrics[\"val_acc_ner\"]    = arr_val_acc_ner\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/training_metrics.json\", 'w') as fp:\n",
    "  json.dump(training_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Losses\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_loss) + 1)), arr_train_loss, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_loss) + 1)), arr_val_loss, label=\"val\")\n",
    "\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_sum) + 1)), arr_train_acc_sum, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_sum) + 1)), arr_val_acc_sum, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy Summary\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_ner) + 1)), arr_train_acc_ner, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_ner) + 1)), arr_val_acc_ner, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy NER\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(arr_val_loss)) + 1\n",
    "model.load(checkpoints_folder + \"/\" + model_name + \"-\" + str(best_epoch) + \".pt\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"doc_splitted\"] = split_all_docs(df_test[args.doc_column_name], False)\n",
    "test_set = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "arr_loss = []\n",
    "arr_loss_sum = []\n",
    "arr_loss_ner = []\n",
    "accuracy_sum = []\n",
    "accuracy_ner = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "counter = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "  for batch in tepoch:\n",
    "    tepoch.set_description(\"Eval model\")\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"], dtype=torch.float).to(device)\n",
    "    targets_sum = torch.tensor(batch[\"labels_sum\"], dtype=torch.float).to(device)\n",
    "    targets_ner = torch.tensor(batch[\"labels_ner\"], dtype=torch.float).to(device)[(input_ids.view(-1) != id_sep) & (input_ids.view(-1) != id_pad)]\n",
    "\n",
    "    y_sum_pred, y_ner_pred = model(input_ids, attention_mask)\n",
    "\n",
    "    loss_sum = criterion(y_sum_pred, targets_sum)\n",
    "    loss_ner = criterion(y_ner_pred, targets_ner)\n",
    "    \n",
    "    loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "\n",
    "    arr_loss.append(loss.item())\n",
    "    arr_loss_sum.append(loss_sum.item())\n",
    "    arr_loss_ner.append(loss_ner.item())\n",
    "\n",
    "    doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "    summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "    probs = np.array(y_sum_pred.tolist()) # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #probs = threshold_probs_by_nb(probs=probs, doc_lens=[probs.shape[0]], average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #probs = threshold_probs_by_prop(probs=probs, doc_lens=[probs.shape[0]], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document)\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in range(min(len(doc), y_sum_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[indices[i]]\n",
    "      y_pred_thresh.append(indices[i])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in y_pred_thresh:#range(min(len(doc), y_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[i]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "    arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "    arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "    accuracy_sum.append(accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=[len(probs)], average_number_of_sentences_per_document=average_number_of_sentences_per_document))\n",
    "    #accuracy.append(accuracy_prop_sent_per_doc_fn(probs=probs, targets=targets.cpu().detach().numpy(), doc_lens=[len(probs)], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document))\n",
    "    accuracy_ner.append(torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0])\n",
    "\n",
    "    tepoch.set_postfix(loss=average(arr_loss), loss_sum=average(arr_loss_sum), loss_ner=average(arr_loss_ner), rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL), accuracy_sum=average(accuracy_sum), accuracy_ner=average(accuracy_ner))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "test_metrics[\"accuracy_sum\"] = average(accuracy_sum)\n",
    "test_metrics[\"accuracy_ner\"] = average(accuracy_ner)\n",
    "test_metrics[\"rouge1\"]   = average(arr_rouge1)\n",
    "test_metrics[\"rouge2\"]   = average(arr_rouge2)\n",
    "test_metrics[\"rougeL\"]   = average(arr_rougeL)\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/test_metrics.json\", 'w') as fp:\n",
    "  json.dump(test_metrics, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"Lead-3\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(min(len(doc), 3)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First n char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"First-n-char'\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(len(doc)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not execute this cell if you want to execute the following cells.\n",
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(train_dataset[0][\"input_ids\"] == 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][\"labels_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2474, 5715, 9765, 8740, 13926, 1011, 9765, 4241, 17155, 16778, 2078, 1012, 102, 2365, 8945, 12514, 9765, 1037, 1016, 1010, 1019, 2463, 1037, 1048, 1005, 9765, 2139, 3002, 1011, 5578, 1011, 1041, 25394, 3366, 3802, 1037, 1022, 2463, 1037, 1048, 1005, 15068, 4355, 2139, 3347, 21031, 3126, 1012, 102, 3393, 18856, 9581, 2102, 21864, 14418, 21162, 5562, 2474, 5715, 9765, 24209, 11475, 8873, 2063, 1010, 4372, 2230, 1010, 2139, 1077, 18856, 9581, 2102, 4153, 7413, 23151, 2278, 1090, 1010, 7367, 7811, 2474, 5939, 18155, 8649, 2666, 4078, 18856, 9581, 3215, 2139, 2474, 2605, 21864, 4012, 13876, 2063, 2632, 5668, 17504, 2102, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 4372, 12609, 1010, 2474, 5715, 24501, 21748, 2102, 4241, 2828, 1077, 18856, 9581, 2102, 4153, 7413, 1090, 18033, 2474, 5579, 27859, 16558, 2666, 11968, 2777, 8780, 1011, 2605, 1010, 21864, 11265, 4012, 13876, 2063, 4078, 2953, 2863, 2483, 1010, 4372, 6765, 10439, 3217, 5403, 1010, 10861, 25022, 2078, 4160, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 8292, 2828, 2139, 18856, 9581, 2102, 7367, 19817, 4215, 14663, 11968, 4078, 7715, 2079, 18796, 2015, 3802, 16655, 20228, 2226, 25500, 11368, 7373, 5816, 3672, 11113, 29067, 10111, 1006, 4372, 14975, 13642, 2278, 4649, 2566, 20689, 23757, 2015, 2310, 16885, 2139, 1048, 1005, 2012, 5802, 28437, 1007, 1010, 16360, 8445, 2666, 2000, 4904, 8740, 2146, 2139, 1048, 1005, 4776, 2063, 13642, 2278, 4895, 26523, 4555, 1040, 1005, 13323, 16429, 2890, 1037, 10768, 19716, 3771, 1012, 102, 4649, 11498, 11368, 6072, 18856, 9581, 28437, 2015, 21864, 2006, 2102, 2566, 15630, 1040, 1521, 27859, 16558, 4313, 2474, 5939, 18155, 8649, 2666, 2139, 2230, 4012, 6442, 4765, 2416, 10857, 10364, 4649, 7715, 3802, 17504, 2102, 10364, 4649, 13511, 2015, 1010, 2123, 2102, 4649, 10380, 9236, 11370, 1037, 2474, 3671, 2063, 3411, 1011, 2456, 1012, 102, 4649, 17419, 4054, 2229, 10857, 14418, 21162, 29196, 2102, 2474, 5715, 2365, 2102, 2556, 10285, 18033, 1048, 1005, 4372, 3540, 16200, 25022, 1011, 19804, 2229, 1012, 102, 13642, 2278, 3393, 2689, 3672, 18856, 9581, 28437, 1010, 8292, 2015, 10857, 2006, 2102, 23408, 4747, 5657, 1012, 102, 16655, 3802, 12672, 19148, 2063, 4372, 2297, 11968, 2474, 3257, 2236, 2063, 2139, 1048, 1005, 4372, 2121, 11239, 3802, 4241, 18856, 9581, 2102, 3143, 2063, 11968, 4078, 25041, 3164, 2229, 3653, 6767, 4183, 4372, 1041, 16020, 2102, 10861, 2474, 4860, 9587, 20684, 2638, 16475, 14995, 2102, 13675, 28100, 2890, 3802, 2474, 20228, 2226, 25500, 11368, 7373, 9587, 20684, 2638, 21790, 18116, 1010, 13642, 2278, 2000, 10421, 14876, 2483, 2139, 24898, 2015, 8358, 3164, 2229, 1012, 102, 8292, 2015, 2689, 8163, 21877, 27346, 2102, 3802, 2890, 9530, 9153, 4570, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2139, 2777, 8780, 1011, 2605, 2474, 4606, 4013, 5403, 1010, 1077, 2175, 10087, 3077, 1090, 1010, 7505, 2474, 5715, 2139, 2175, 10087, 3077, 1011, 3393, 1996, 4014, 1010, 28616, 2063, 4372, 2326, 4372, 3851, 3802, 21864, 7367, 19817, 7140, 3726, 1037, 1023, 2463, 1037, 5285, 1040, 1005, 1051, 5562, 4887, 1010, 1010, 15068, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 9765, 2139, 2184, 1010, 1021, 6362, 3802, 2474, 18535, 3126, 2139, 13511, 2015, 2139, 6205, 2683, 1010, 1021, 3461, 10364, 2474, 2558, 2063, 3261, 1011, 2230, 1012, 102, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2010, 29469, 4226, 2474, 4606, 4013, 5403, 1010, 1077, 24188, 20431, 1516, 5003, 6279, 8743, 2271, 1090, 1010, 7505, 2474, 5715, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 28616, 2063, 4372, 2326, 4372, 4437, 3802, 1037, 2539, 2463, 1010, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 23408, 4747, 5657, 2139, 2184, 1010, 1018, 6362, 10364, 2474, 2558, 2063, 3411, 1011, 2456, 1037, 2184, 1010, 1021, 6362, 10364, 3261, 1011, 2230, 1010, 16405, 2483, 1037, 2340, 1010, 1015, 6362, 10364, 2889, 1011, 12609, 1012, 102, 13075, 7140, 3077, 9765, 16655, 5715, 3541, 2063, 1010, 2482, 15317, 26208, 2102, 2112, 2666, 4078, 16569, 21877, 2226, 15068, 24403, 21877, 2226, 9742, 2015, 1010, 8740, 12411, 2015, 2139, 2474, 26192, 15029, 2063, 2139, 7939, 28032, 2063, 2139, 1048, 1005, 16021, 4402, 1010, 1010, 1010, 1012, 102, 11968, 9932, 6216, 9236, 2474, 5715, 26208, 2102, 2112, 2666, 2139, 1048, 1005, 2250, 2063, 1040, 1005, 8432, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 2123, 2102, 15317, 9765, 16655, 5715, 2139, 2474, 2522, 21017, 2638, 1012, 102, 8292, 4674, 2250, 2063, 1010, 21864, 19723, 22107, 2063, 6255, 16569, 1010, 9765, 4937, 20265, 29346, 2063, 18033, 4649, 9149, 2139, 2753, 2199, 1037, 25175, 3619, 2139, 3263, 2199, 10427, 11390, 1010, 1012, 102, 1048, 1005, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1010, 2425, 2063, 24209, 1005, 15317, 24501, 21748, 2102, 2139, 2474, 2918, 2139, 2123, 24045, 2015, 2885, 24336, 1040, 1521, 6139, 16012, 21281, 5332, 4226, 4078, 14017, 2015, 2522, 11467, 2455, 3104, 1006, 18856, 2278, 1007, 1010, 9765, 9388, 4226, 2063, 11968, 1048, 1005, 5197, 4078, 26568, 3406, 7442, 2015, 12943, 7277, 29111, 1006, 2531, 1003, 4372, 2760, 1007, 1010, 16655, 10817, 8909, 4765, 7413, 1037, 3526, 2063, 2139, 2901, 1006, 2531, 1003, 1007, 1012, 102, 2474, 16360, 8445, 22753, 6987, 10559, 4372, 2760, 9765, 2474, 24086, 18941, 2063, 1024, 10996, 2015, 1006, 4805, 1003, 1007, 1010, 25170, 2015, 5424, 4244, 1006, 4229, 1010, 1019, 1003, 1007, 1010, 10019, 12943, 7277, 29111, 21770, 10624, 6914, 2229, 1006, 2321, 1010, 1019, 1003, 1007, 1012, 102, 1048, 1005, 16270, 2777, 11968, 9932, 6216, 9236, 1037, 22137, 4895, 2041, 4014, 4372, 5622, 10177, 2566, 11368, 5794, 2102, 2139, 12826, 2099, 1048, 1521, 6622, 18033, 3393, 29023, 2139, 1048, 1521, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1006, 15068, 2139, 26568, 3406, 7442, 2015, 1037, 4078, 14925, 18223, 2229, 2367, 2229, 1007, 1012, 102, 4606, 17301, 2869, 4958, 2080, 10997, 2365, 2102, 7801, 2015, 27411, 2433, 2063, 2139, 11122, 2229, 15068, 7760, 29347, 23144, 5267, 1024, 2474, 11122, 2063, 2139, 16220, 5498, 1006, 16855, 6137, 2063, 9033, 8586, 2571, 1007, 1010, 2474, 11122, 2063, 1040, 1005, 17997, 1011, 2350, 1006, 11102, 1011, 7647, 1007, 3802, 2474, 2558, 2063, 2552, 16284, 2571, 1006, 3925, 1037, 8740, 23099, 4103, 1005, 17504, 1007, 1012, 102, 3393, 2053, 2213, 2139, 2474, 2334, 4221, 9765, 2012, 22199, 2063, 27411, 4649]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nLa commune est au nord-est du Cotentin. Son bourg est à 2,5 km à l'est de Saint-Pierre-Église et à 8 km à l'ouest de Barfleur.\\n\\n\\nLe climat qui caractérise la commune est qualifié, en 2010, de « climat océanique franc », selon la typologie des climats de la France qui compte alors huit grands types de climats en métropole. En 2020, la commune ressort du type « climat océanique » dans la classification établie par Météo-France, qui ne compte désormais, en première approche, que cinq grands types de climats en métropole. Ce type de climat se traduit par des températures douces et une pluviométrie relativement abondante (en liaison avec les perturbations venant de l'Atlantique), répartie tout au long de l'année avec un léger maximum d'octobre à février.\\nLes paramètres climatiques qui ont permis d’établir la typologie de 2010 comportent six variables pour les températures et huit pour les précipitations, dont les valeurs correspondent à la normale 1971-2000. Les sept principales variables caractérisant la commune sont présentées dans l'encadré ci-après.\\n\\nAvec le changement climatique, ces variables ont évolué. Une étude réalisée en 2014 par la Direction générale de l'Énergie et du Climat complétée par des études régionales prévoit en effet que la température moyenne devrait croître et la pluviométrie moyenne baisser, avec toutefois de fortes variations régionales. Ces changements peuvent être constatés sur la station météorologique de Météo-France la plus proche, « Gonneville », sur la commune de Gonneville-Le Theil, mise en service en 1959 et qui se trouve à 9 km à vol d'oiseau,, où la température moyenne annuelle est de 10,7 °C et la hauteur de précipitations de 919,7 mm pour la période 1981-2010.\\nSur la station météorologique historique la plus proche, « Cherbourg – Maupertus », sur la commune de Cherbourg-en-Cotentin, mise en service en 1935 et à 19 km, la température moyenne annuelle évolue de 10,4 °C pour la période 1971-2000 à 10,7 °C pour 1981-2010, puis à 11,1 °C pour 1991-2020.\\n\\n\\n\\n\\nVarouville est une commune rurale, car elle fait partie des communes peu ou très peu denses, au sens de la grille communale de densité de l'Insee,,,.\\nPar ailleurs la commune fait partie de l'aire d'attraction de Cherbourg-en-Cotentin, dont elle est une commune de la couronne. Cette aire, qui regroupe 77 communes, est catégorisée dans les aires de 50 000 à moins de 200 000 habitants,.\\n\\n\\n\\nL'occupation des sols de la commune, telle qu'elle ressort de la base de données européenne d’occupation biophysique des sols Corine Land Cover (CLC), est marquée par l'importance des territoires agricoles (100 % en 2018), une proportion identique à celle de 1990 (100 %). La répartition détaillée en 2018 est la suivante : prairies (46 %), terres arables (38,5 %), zones agricoles hétérogènes (15,5 %).\\nL'IGN met par ailleurs à disposition un outil en ligne permettant de comparer l’évolution dans le temps de l’occupation des sols de la commune (ou de territoires à des échelles différentes). Plusieurs époques sont accessibles sous forme de cartes ou photos aériennes : la carte de Cassini (XVIIIe siècle), la carte d'état-major (1820-1866) et la période actuelle (1950 à aujourd'hui).\\n\\n\\nLe nom de la localité est attesté sous les formes Vasrouvilla (sans date), Warouvilla en 1280, Varrouvilla vers 1280.\\nLe toponyme est basé sur un anthroponyme germanique tel que Warald ou Warulfus,, (forme latinisée, comprendre Warulf/Warolf cf. Warulfe Ier d'Uxelles) et sur l'ancien français ville/vile dans son sens originel de « domaine rural » issu du latin villa rustica.\\nRemarque : le même nom de personne est attesté au moins une seconde fois en Normandie dans Montgaroult (Orne, Mons Warulfi 1063), cette commune se trouvant au sud de l'isoglosse w- / g(u)- (qui est parallèle à la ligne Joret en Normandie), d'où le passage de [w] > [g], alors que dans Varouville, il s'agit de l'évolution secondaire [w] > [v] qui s'est produite seulement à partir du XIIe siècle.\\nLe gentilé est Varouvillais.\\n\\n\\nEntre 1911 et 1950, la commune est traversée par le « Tue-Vaques », le chemin de fer entre Cherbourg et Barfleur, dont on peut encore voir l'ancienne gare à l'architecture du XXe siècle, près de l'église.\\n\\n\\n\\nLe conseil municipal est composé de onze membres dont le maire et deux adjoints.\\n\\n\\nL'évolution du nombre d'habitants est connue à travers les recensements de la population effectués dans la commune depuis 1793. À partir de 2006, les populations légales des communes sont publiées annuellement par l'Insee. Le recensement repose désormais sur une collecte d'information annuelle, concernant successivement tous les territoires communaux au cours d'une période de cinq ans. Pour les communes de moins de 10 000 habitants, une enquête de recensement portant sur toute la population est réalisée tous les cinq ans, les populations légales des années intermédiaires étant quant à elles estimées par interpolation ou extrapolation. Pour la commune, le premier recensement exhaustif entrant dans le cadre du nouveau dispositif a été réalisé en 2005.\\nEn 2020, la commune comptait 233 habitants, en diminution de 12,08 % par rapport à 2014 (Manche : −0,97 %, France hors Mayotte : +1,9 %).\\nVarouville a compté jusqu'à 519 habitants en 1806.\\n\\n\\n\\n\\n\\nÉglise Saint-Martin (XIIIe siècle) avec son clocher en bâtière bâti en 1710, dont le mobilier fut fortement endommagé pendant la Révolution. Elle abrite une sculpture charité Saint-Martin avec donateur en pierre calcaire de la fin du XVe classée au titre objet aux monuments historiques. Elle formait à l'origine tympan au-dessus de la porte d'entrée de l'église et fut déplacée à l'intérieur de la nef afin d'être mieux conservée. Le donateur sans tête est représenté en prière, avec probablement son épouse derrière lui, à gauche du groupe sculpté. .\\nChâteau de la Bréhoulle.\\nAncienne gare, près de l'église, de la ligne de chemin de fer de Cherbourg à Barfleur où s'arrêtait le « tue-vaques ».\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"flat_contents\"][df_train.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3002, 1011, 5578, 1011, 1041, 25394, 3366]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.encode(\"Saint-Pierre-Église\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"labels_ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "10\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "14\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(sum(train_dataset[i][\"labels_ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID du token [SEP]: 102\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "\n",
    "print(f\"ID du token [SEP]: {sep_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(len(train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
