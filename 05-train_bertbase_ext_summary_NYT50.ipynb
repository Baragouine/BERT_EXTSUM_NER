{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Bert for extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import statistics\n",
    "import os\n",
    "from utils.split_all_docs import split_all_docs\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.DataLoader import DataLoader\n",
    "from utils.preprocess_df import preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "  try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "      return True   # Jupyter notebook or qtconsole\n",
    "    elif shell == 'TerminalInteractiveShell':\n",
    "      return False  # Terminal running IPython\n",
    "    else:\n",
    "      return False  # Other type (?)\n",
    "  except NameError:\n",
    "    return False      # Probably standard Python interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse args if script mode\n",
    "parser = argparse.ArgumentParser(description='extractive summary and ner using bert')\n",
    "\n",
    "parser.add_argument('-is_graphic',type=int,default=1,choices=[0,1])\n",
    "parser.add_argument('-gpu_num',type=int,default=0)\n",
    "parser.add_argument('-batch_size',type=int,default=4)#32)\n",
    "parser.add_argument('-epochs',type=int,default=100)\n",
    "parser.add_argument('-dataset',type=str,default=\"data/nyt_corpus_LDC2008T19_50.json\")\n",
    "\n",
    "args = None\n",
    "\n",
    "if is_notebook():\n",
    "  args = parser.parse_args(\"\")\n",
    "else:\n",
    "  args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse:\n",
      "is_graphic: True\n",
      "cuda_num: 0\n",
      "epochs 100\n",
      "batch_size 4\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "is_graphic = args.is_graphic != 0\n",
    "cuda_num = args.gpu_num\n",
    "bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# hyper-parameters\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "learning_rate = 1e-3\n",
    "early_stopping = 3\n",
    "model_name = \"05-train_bertbase_ext_summary_NYT50\"\n",
    "sub_folder_name = \"model_name__{}__time__{}__lr__{}__batch_size__{}__cuda_num__{}__early_stopping__{}\".format(model_name, time(), learning_rate, batch_size, cuda_num, early_stopping)\n",
    "checkpoints_folder = \"./checkpoints/\" + sub_folder_name\n",
    "loss_sum_coef = 0.5\n",
    "loss_ner_coef = 0.5\n",
    "average_number_of_sentences_per_document = 3\n",
    "\n",
    "# print\n",
    "print(\"parse:\")\n",
    "print(\"is_graphic:\", is_graphic)\n",
    "print(\"cuda_num:\", cuda_num)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 6\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 2: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 3: NVIDIA GeForce GTX 1080\n",
      "GPU 4: NVIDIA GeForce GTX 1080\n",
      "GPU 5: NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "  # Display the number of available GPUs\n",
    "  print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "  # Display the name of each GPU\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"MPS available.\")\n",
    "else:\n",
    "  print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:\" + str(cuda_num) \n",
    "elif torch.backends.mps.is_available():\n",
    "  dev = torch.device(\"mps\")\n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(l):\n",
    "  return sum(l) / len(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.dataset)\n",
    "df = shuffle(df, random_state=0)\n",
    "\n",
    "df_test = df.iloc[0:3452]\n",
    "df_val = df.iloc[3452:7452]\n",
    "df_train = df.iloc[7452:9452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats corpus\n",
    "\n",
    "if False:\n",
    "  len_articles = []\n",
    "\n",
    "  for idx in df.index:\n",
    "    txt = df[\"flat_contents\"][idx]\n",
    "    txt = sent_tokenize(txt)\n",
    "    txt = \" [SEP] \".join(txt)\n",
    "    txt = bert_tokenizer.encode(txt, add_special_tokens=False)\n",
    "    len_articles.append(len(txt))\n",
    "\n",
    "  print(\"max:\", max(len_articles), \", mediane:\", statistics.median(len_articles), \", avg:\", average(len_articles), \", std:\", statistics.stdev(len_articles))\n",
    "  # max: 184812 , mediane: 862.5 , avg: 2146.653203237274 , std: 4145.829631357804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>docs</th>\n",
       "      <th>summaries</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419141</th>\n",
       "      <td>data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...</td>\n",
       "      <td>\\n        The dim, dank bathroom was the scene...</td>\n",
       "      <td>\\n        Woman and her 16-year-old nephew are...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599153</th>\n",
       "      <td>data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...</td>\n",
       "      <td>\\n        As Iraqi investigators began searchi...</td>\n",
       "      <td>\\n        Iraq's Sunni Arab leaders accuse Shi...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    paths  \\\n",
       "419141  data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...   \n",
       "599153  data/nyt_corpus_LDC2008T19/nyt_corpus/data/200...   \n",
       "\n",
       "                                                     docs  \\\n",
       "419141  \\n        The dim, dank bathroom was the scene...   \n",
       "599153  \\n        As Iraqi investigators began searchi...   \n",
       "\n",
       "                                                summaries  \\\n",
       "419141  \\n        Woman and her 16-year-old nephew are...   \n",
       "599153  \\n        Iraq's Sunni Arab leaders accuse Shi...   \n",
       "\n",
       "                                                   labels  \n",
       "419141  [1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "599153  [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_df(df=df_train, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)\n",
    "val_dataset = preprocess_df(df=df_val, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)\n",
    "test_dataset = preprocess_df(df=df_test, bert_tokenizer=bert_tokenizer, block_size=512, trunc_doc=50, doc_column_name=\"docs\", labels_sum_column_name=\"labels\", is_sep_n=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prop=0.1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertExtSUMNER(nn.Module):\n",
    "  def __init__(self, bert_layer, bert_tokenizer, dim_emb=768) -> None:\n",
    "    super(BertExtSUMNER, self).__init__()\n",
    "    self.bert_layer = bert_layer\n",
    "    self.bert_tokenizer = bert_tokenizer\n",
    "    self.dim_emb = dim_emb\n",
    "\n",
    "    # predict summary\n",
    "    self.w_sum = nn.Linear(dim_emb, 1)\n",
    "    \n",
    "    # NER\n",
    "    self.w_ner = nn.Linear(dim_emb, 1)\n",
    "\n",
    "  def forward(self, list_input_ids, list_attention_mask):\n",
    "    id_sep = bert_tokenizer.sep_token_id\n",
    "    id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in range(len(list_input_ids)):\n",
    "      input_ids.append(list_input_ids[i].to(self.bert_layer.device))\n",
    "      attention_mask.append(list_attention_mask[i].to(self.bert_layer.device))\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "\n",
    "    x = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    mask_sep = (input_ids == id_sep).view(-1)\n",
    "    mask_not_sep = (torch.ne(input_ids, bert_tokenizer.pad_token_id) & torch.ne(input_ids, bert_tokenizer.sep_token_id)).view(-1)\n",
    "    x = x.last_hidden_state\n",
    "    x = x.view(-1, x.size(-1))\n",
    "    emb_sent = x[mask_sep, :]\n",
    "    emb_entities = x[mask_not_sep, :]\n",
    "\n",
    "    o_sum = self.w_sum(emb_sent)\n",
    "    o_sum = torch.sigmoid(o_sum).squeeze(-1)\n",
    "\n",
    "    o_ner = self.w_ner(emb_entities)\n",
    "    o_ner = torch.sigmoid(o_ner).squeeze(-1)\n",
    "\n",
    "    return o_sum, o_ner\n",
    "\n",
    "  def save(self, fname):\n",
    "    torch.save(self.state_dict(), fname)\n",
    "\n",
    "  def load(self, fname):\n",
    "    self.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoints_folder):\n",
    "  os.makedirs(checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_549284/1346601038.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"doc_splitted\"] = split_all_docs(df_val[\"docs\"])\n"
     ]
    }
   ],
   "source": [
    "df_val[\"doc_splitted\"] = split_all_docs(df_val[\"docs\"])\n",
    "val_set = df_val\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 3batch [00:02,  1.29batch/s, loss=1.3, loss_sum=1.3]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : val loss = 0.765, val loss summary = 0.765, r1 = 0.347, r2 = 0.127, rL = 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 3batch [00:02,  1.33batch/s, loss=0.781, loss_sum=0.781]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : val loss = 1.170, val loss summary = 1.170, r1 = 0.359, r2 = 0.142, rL = 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 3batch [00:02,  1.41batch/s, loss=0.754, loss_sum=0.754]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : val loss = 0.693, val loss summary = 0.693, r1 = 0.295, r2 = 0.085, rL = 0.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 3batch [00:02,  1.38batch/s, loss=0.7, loss_sum=0.7]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : val loss = 0.694, val loss summary = 0.694, r1 = 0.389, r2 = 0.179, rL = 0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 3batch [00:02,  1.35batch/s, loss=0.713, loss_sum=0.713]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : val loss = 0.694, val loss summary = 0.694, r1 = 0.393, r2 = 0.181, rL = 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 3batch [00:02,  1.37batch/s, loss=0.699, loss_sum=0.699]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : val loss = 0.701, val loss summary = 0.701, r1 = 0.367, r2 = 0.151, rL = 0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 3batch [00:02,  1.35batch/s, loss=0.698, loss_sum=0.698]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : val loss = 0.693, val loss summary = 0.693, r1 = 0.393, r2 = 0.184, rL = 0.278\n",
      "Training duration = 68.65984153747559\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "arr_train_loss = []\n",
    "arr_train_loss_sum = []\n",
    "#arr_train_loss_ner = []\n",
    "#arr_train_acc_sum = []\n",
    "#arr_train_acc_ner = []\n",
    "arr_val_loss = []\n",
    "#arr_val_acc_sum = []\n",
    "#arr_val_acc_ner = []\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  # Train\n",
    "  model.train()\n",
    "  nb_batch_train = 0\n",
    "  nb_loss_train = 0\n",
    "  total_train_loss = 0\n",
    "  total_train_loss_sum = 0\n",
    "  #total_train_loss_ner = 0\n",
    "  #total_train_acc_sum = 0\n",
    "  #total_train_acc_ner = 0\n",
    "  \n",
    "  id_sep = bert_tokenizer.sep_token_id\n",
    "  id_pad = bert_tokenizer.pad_token\n",
    "\n",
    "  for i in range(len(train_loader)):\n",
    "    train_loader[i]\n",
    "\n",
    "  with tqdm(train_loader, unit=\"batch\", total=len(train_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "      tepoch.set_description(f\"Epoch {epoch}\")\n",
    "      #if dev != \"cpu\":\n",
    "      #  torch.cuda.empty_cache()\n",
    "      list_input_ids = batch[\"input_ids\"]\n",
    "      list_attention_mask = batch[\"attention_mask\"]\n",
    "      list_targets_sum = batch[\"labels\"]\n",
    "      #list_targets_ner = batch[\"labels_ner\"]\n",
    "      \n",
    "      list_y_sum_pred = []\n",
    "      #list_y_ner_pred = []\n",
    "      for i in range(len(list_input_ids)):\n",
    "        y_sum_pred, y_ner_pred = model(list_input_ids[i:i+1], list_attention_mask[i:i+1])\n",
    "\n",
    "        loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[i], dtype=torch.float).to(device))\n",
    "        #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[i], dtype=torch.float).to(device))\n",
    "        \n",
    "        #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "        loss = loss_sum\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        nb_loss_train += 1\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_loss_sum += loss_sum.item()\n",
    "        #total_train_loss_ner += loss_ner.item()\n",
    "\n",
    "        list_y_sum_pred.append(y_sum_pred.detach())\n",
    "        #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "      nb_batch_train += 1\n",
    "\n",
    "      y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "      #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "      targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "      #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "      probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "      probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "      #total_train_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "      tepoch.set_postfix(loss=total_train_loss/nb_loss_train, loss_sum=total_train_loss_sum/nb_loss_train)\n",
    "\n",
    "  # Save model\n",
    "  model.save(checkpoints_folder + \"/\" + model_name + \"-\" + str(epoch) + \".pt\")\n",
    "\n",
    "  # Eval\n",
    "  model.eval()\n",
    "  nb_batch_val = 0\n",
    "  nb_loss_val = 0\n",
    "  total_val_loss = 0\n",
    "  total_val_loss_sum = 0\n",
    "  #total_val_loss_ner = 0\n",
    "  #total_val_acc_sum = 0\n",
    "  #total_val_acc_ner = 0\n",
    "  total_r1 = 0\n",
    "  total_r2 = 0\n",
    "  total_rl = 0\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  for i, batch in enumerate(val_loader):\n",
    "    #if dev != \"cpu\":\n",
    "    #  torch.cuda.empty_cache()\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "      \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      nb_loss_val += 1      \n",
    "      total_val_loss += loss.item()\n",
    "      total_val_loss_sum += loss_sum.item()\n",
    "      #total_val_loss_ner += loss_ner.item()\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    nb_batch_val += 1\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "    #targets_ner = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_ner])\n",
    "\n",
    "    doc = val_set[\"doc_splitted\"].iloc[i]\n",
    "    summaries = val_set[\"summaries\"].iloc[i]\n",
    "\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    doc_lens = [len(doc)]\n",
    "    for j in range(doc_lens[0]):\n",
    "      txt = txt + \". \" + doc[indices[j]]\n",
    "      y_pred_thresh.append(indices[j])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for j in y_pred_thresh:\n",
    "      txt = txt + \". \" + doc[j]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    total_r1 += scores[\"rouge1\"].recall\n",
    "    total_r2 += scores[\"rouge2\"].recall\n",
    "    total_rl += scores[\"rougeL\"].recall\n",
    "\n",
    "    probs = y_sum_pred.tolist() # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #total_val_acc_sum += accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=doc_lens, average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #total_val_acc_ner += torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0]\n",
    "\n",
    "  print(\"Epoch {} : val loss = {:.3f}, val loss summary = {:.3f}, r1 = {:.3f}, r2 = {:.3f}, rL = {:.3f}\".format(epoch, total_val_loss / nb_loss_val, total_val_loss_sum / nb_loss_val, total_r1 / nb_batch_val, total_r2 / nb_batch_val, total_rl / nb_batch_val))\n",
    "\n",
    "  if len(arr_val_loss) >= early_stopping+1:\n",
    "    if min(arr_val_loss[-early_stopping:]) >= arr_val_loss[-(early_stopping+1)]:\n",
    "      break\n",
    "\n",
    "  del loss\n",
    "  del loss_sum\n",
    "  del y_sum_pred\n",
    "  del y_ner_pred\n",
    "\n",
    "  if dev != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  arr_train_loss.append(total_train_loss / nb_batch_train)\n",
    "  \n",
    "  #arr_train_acc_sum.append(total_train_acc_sum / nb_batch_train)\n",
    "  #arr_train_acc_ner.append(total_train_acc_ner / nb_batch_train)\n",
    "\n",
    "  arr_val_loss.append(total_val_loss / nb_batch_val)\n",
    "  #arr_val_acc_sum.append(total_val_acc_sum / nb_batch_val)\n",
    "  #arr_val_acc_ner.append(total_val_acc_ner / nb_batch_val)\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = {}\n",
    "training_metrics[\"duration\"]   = t2 - t1\n",
    "training_metrics[\"train_loss\"] = arr_train_loss\n",
    "#training_metrics[\"train_acc_sum\"]  = arr_train_acc_sum\n",
    "#training_metrics[\"train_acc_ner\"]  = arr_train_acc_ner\n",
    "training_metrics[\"val_loss\"]   = arr_val_loss\n",
    "#training_metrics[\"val_acc_sum\"]    = arr_val_acc_sum\n",
    "#training_metrics[\"val_acc_ner\"]    = arr_val_acc_ner\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/training_metrics.json\", 'w') as fp:\n",
    "  json.dump(training_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw Losses\n",
    "if is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_loss) + 1)), arr_train_loss, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_loss) + 1)), arr_val_loss, label=\"val\")\n",
    "\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_sum) + 1)), arr_train_acc_sum, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_sum) + 1)), arr_val_acc_sum, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy Summary\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw Accuracies\n",
    "if False and is_graphic:\n",
    "  plt.plot(list(range(1, len(arr_train_acc_ner) + 1)), arr_train_acc_ner, label=\"train\")\n",
    "  plt.plot(list(range(1, len(arr_val_acc_ner) + 1)), arr_val_acc_ner, label=\"val\")\n",
    "\n",
    "  plt.title(\"Accuracy NER\")\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertExtSUMNER(bert_layer=bert_layer, bert_tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch = np.argmin(np.array(arr_val_loss)) + 1\n",
    "model.load(checkpoints_folder + \"/\" + model_name + \"-\" + str(best_epoch) + \".pt\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_549284/147892152.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"doc_splitted\"] = split_all_docs(df_test[\"docs\"], False)\n"
     ]
    }
   ],
   "source": [
    "df_test[\"doc_splitted\"] = split_all_docs(df_test[\"docs\"], False)\n",
    "test_set = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval model: 100%|██████████| 100/100 [00:07<00:00, 13.21batch/s, loss=0.693, loss_sum=0.693, rouge1=0.282, rouge2=0.0705, rougeL=0.165]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "arr_loss = []\n",
    "arr_loss_sum = []\n",
    "#arr_loss_ner = []\n",
    "#accuracy_sum = []\n",
    "#accuracy_ner = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "counter = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "  for batch in tepoch:\n",
    "    tepoch.set_description(\"Eval model\")\n",
    "    list_input_ids = batch[\"input_ids\"]\n",
    "    list_attention_mask = batch[\"attention_mask\"]\n",
    "    list_targets_sum = batch[\"labels\"]\n",
    "\n",
    "    list_y_sum_pred = []\n",
    "    #list_y_ner_pred = []\n",
    "    for j in range(len(list_input_ids)):\n",
    "      y_sum_pred, y_ner_pred = model(list_input_ids[j:j+1], list_attention_mask[j:j+1])\n",
    "\n",
    "      loss_sum = criterion(y_sum_pred, torch.tensor(list_targets_sum[j], dtype=torch.float).to(device))\n",
    "      #loss_ner = criterion(y_ner_pred, torch.tensor(list_targets_ner[j], dtype=torch.float).to(device))\n",
    "    \n",
    "      #loss = loss_sum_coef * loss_sum + loss_ner_coef * loss_ner\n",
    "      loss = loss_sum\n",
    "\n",
    "      arr_loss.append(loss.item())\n",
    "      arr_loss_sum.append(loss_sum.item())\n",
    "      #arr_loss_ner.append(loss_ner.item())\n",
    "\n",
    "      list_y_sum_pred.append(y_sum_pred.detach())\n",
    "      #list_y_ner_pred.append(y_ner_pred.detach())\n",
    "\n",
    "    y_sum_pred = torch.cat(list_y_sum_pred)\n",
    "    #y_ner_pred = torch.cat(list_y_ner_pred)\n",
    "    #targets_sum = torch.cat([torch.tensor(e, dtype=torch.float).to(device) for e in list_targets_sum])\n",
    "\n",
    "    doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "    summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "    probs = np.array(y_sum_pred.tolist()) # compute_probs(y_pred)\n",
    "    probs_tensor = y_sum_pred #torch.tensor(probs, dtype=torch.float).to(device)\n",
    "\n",
    "    #probs = threshold_probs_by_nb(probs=probs, doc_lens=[probs.shape[0]], average_number_of_sentences_per_document=average_number_of_sentences_per_document)\n",
    "    #probs = threshold_probs_by_prop(probs=probs, doc_lens=[probs.shape[0]], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document)\n",
    "    indices = torch.argsort(y_sum_pred, descending=True)\n",
    "\n",
    "    y_pred_thresh = []\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in range(min(len(doc), y_sum_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[indices[i]]\n",
    "      y_pred_thresh.append(indices[i])\n",
    "      if len(txt) >= len(summaries):\n",
    "        break\n",
    "\n",
    "    y_pred_thresh.sort()\n",
    "\n",
    "    txt = \"\"\n",
    "\n",
    "    for i in y_pred_thresh:#range(min(len(doc), y_pred.shape[0])):\n",
    "      txt = txt + \". \" + doc[i]\n",
    "\n",
    "    n = min(len(txt), len(summaries))\n",
    "\n",
    "    while n < len(txt) and txt[n].isalnum():\n",
    "      n += 1\n",
    "\n",
    "    txt = txt[:n]\n",
    "\n",
    "    # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "    scores = scorer.score(summaries, txt)\n",
    "    arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "    arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "    arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "    #accuracy_sum.append(accuracy_nb_sent_per_doc_fn(probs=probs, targets=targets_sum.cpu().detach().numpy(), doc_lens=[len(probs)], average_number_of_sentences_per_document=average_number_of_sentences_per_document))\n",
    "    #accuracy.append(accuracy_prop_sent_per_doc_fn(probs=probs, targets=targets.cpu().detach().numpy(), doc_lens=[len(probs)], average_proportion_of_sentences_per_document=average_proportion_of_sentences_per_document))\n",
    "    #accuracy_ner.append(torch.sum(((y_ner_pred > 0.5).float() == targets_ner).float()).item() / targets_ner.shape[0])\n",
    "\n",
    "    tepoch.set_postfix(loss=average(arr_loss), loss_sum=average(arr_loss_sum), rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "#test_metrics[\"accuracy_sum\"] = average(accuracy_sum)\n",
    "#test_metrics[\"accuracy_ner\"] = average(accuracy_ner)\n",
    "test_metrics[\"rouge1\"]   = average(arr_rouge1)\n",
    "test_metrics[\"rouge2\"]   = average(arr_rouge2)\n",
    "test_metrics[\"rougeL\"]   = average(arr_rougeL)\n",
    "\n",
    "# Save to file in JSON format\n",
    "\n",
    "with open(checkpoints_folder + \"/test_metrics.json\", 'w') as fp:\n",
    "  json.dump(test_metrics, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lead-3: 100%|██████████| 100/100 [00:00<00:00, 103.98batch/s, rouge1=0.393, rouge2=0.217, rougeL=0.299]\n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"Lead-3\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(min(len(doc), 3)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        # assert len(txt) - len(summaries) <= 20\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First n char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "First-n-char': 100%|██████████| 100/100 [00:01<00:00, 91.19batch/s, rouge1=0.453, rouge2=0.25, rougeL=0.338] \n"
     ]
    }
   ],
   "source": [
    "arr_rouge1 = []\n",
    "arr_rouge2 = []\n",
    "arr_rougeL = []\n",
    "accuracy = []\n",
    "\n",
    "idx = 0\n",
    "with tqdm(test_loader, unit=\"batch\", total=len(test_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(\"First-n-char'\")\n",
    "        doc = test_set[\"doc_splitted\"].iloc[idx]\n",
    "\n",
    "        txt = \"\"\n",
    "\n",
    "        for i in range(len(doc)):\n",
    "            txt = txt + doc[i]\n",
    "\n",
    "        summaries = test_set[\"summaries\"].iloc[idx]\n",
    "\n",
    "        n = min(len(txt), len(summaries))\n",
    "\n",
    "        while n < len(txt) and txt[n].isalnum():\n",
    "            n += 1\n",
    "\n",
    "        txt = txt[:n]\n",
    "\n",
    "        scores = scorer.score(summaries, txt)\n",
    "        arr_rouge1.append(scores[\"rouge1\"].recall)\n",
    "        arr_rouge2.append(scores[\"rouge2\"].recall)\n",
    "        arr_rougeL.append(scores[\"rougeL\"].recall)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        tepoch.set_postfix(rouge1 = average(arr_rouge1), rouge2 = average(arr_rouge2), rougeL = average(arr_rougeL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raoufdine/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Does not execute this cell if you want to execute the following cells.\n",
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(train_dataset[0][\"input_ids\"] == 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][\"labels_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2474, 5715, 9765, 8740, 13926, 1011, 9765, 4241, 17155, 16778, 2078, 1012, 102, 2365, 8945, 12514, 9765, 1037, 1016, 1010, 1019, 2463, 1037, 1048, 1005, 9765, 2139, 3002, 1011, 5578, 1011, 1041, 25394, 3366, 3802, 1037, 1022, 2463, 1037, 1048, 1005, 15068, 4355, 2139, 3347, 21031, 3126, 1012, 102, 3393, 18856, 9581, 2102, 21864, 14418, 21162, 5562, 2474, 5715, 9765, 24209, 11475, 8873, 2063, 1010, 4372, 2230, 1010, 2139, 1077, 18856, 9581, 2102, 4153, 7413, 23151, 2278, 1090, 1010, 7367, 7811, 2474, 5939, 18155, 8649, 2666, 4078, 18856, 9581, 3215, 2139, 2474, 2605, 21864, 4012, 13876, 2063, 2632, 5668, 17504, 2102, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 4372, 12609, 1010, 2474, 5715, 24501, 21748, 2102, 4241, 2828, 1077, 18856, 9581, 2102, 4153, 7413, 1090, 18033, 2474, 5579, 27859, 16558, 2666, 11968, 2777, 8780, 1011, 2605, 1010, 21864, 11265, 4012, 13876, 2063, 4078, 2953, 2863, 2483, 1010, 4372, 6765, 10439, 3217, 5403, 1010, 10861, 25022, 2078, 4160, 2882, 2015, 4127, 2139, 18856, 9581, 3215, 4372, 6005, 15049, 1012, 102, 8292, 2828, 2139, 18856, 9581, 2102, 7367, 19817, 4215, 14663, 11968, 4078, 7715, 2079, 18796, 2015, 3802, 16655, 20228, 2226, 25500, 11368, 7373, 5816, 3672, 11113, 29067, 10111, 1006, 4372, 14975, 13642, 2278, 4649, 2566, 20689, 23757, 2015, 2310, 16885, 2139, 1048, 1005, 2012, 5802, 28437, 1007, 1010, 16360, 8445, 2666, 2000, 4904, 8740, 2146, 2139, 1048, 1005, 4776, 2063, 13642, 2278, 4895, 26523, 4555, 1040, 1005, 13323, 16429, 2890, 1037, 10768, 19716, 3771, 1012, 102, 4649, 11498, 11368, 6072, 18856, 9581, 28437, 2015, 21864, 2006, 2102, 2566, 15630, 1040, 1521, 27859, 16558, 4313, 2474, 5939, 18155, 8649, 2666, 2139, 2230, 4012, 6442, 4765, 2416, 10857, 10364, 4649, 7715, 3802, 17504, 2102, 10364, 4649, 13511, 2015, 1010, 2123, 2102, 4649, 10380, 9236, 11370, 1037, 2474, 3671, 2063, 3411, 1011, 2456, 1012, 102, 4649, 17419, 4054, 2229, 10857, 14418, 21162, 29196, 2102, 2474, 5715, 2365, 2102, 2556, 10285, 18033, 1048, 1005, 4372, 3540, 16200, 25022, 1011, 19804, 2229, 1012, 102, 13642, 2278, 3393, 2689, 3672, 18856, 9581, 28437, 1010, 8292, 2015, 10857, 2006, 2102, 23408, 4747, 5657, 1012, 102, 16655, 3802, 12672, 19148, 2063, 4372, 2297, 11968, 2474, 3257, 2236, 2063, 2139, 1048, 1005, 4372, 2121, 11239, 3802, 4241, 18856, 9581, 2102, 3143, 2063, 11968, 4078, 25041, 3164, 2229, 3653, 6767, 4183, 4372, 1041, 16020, 2102, 10861, 2474, 4860, 9587, 20684, 2638, 16475, 14995, 2102, 13675, 28100, 2890, 3802, 2474, 20228, 2226, 25500, 11368, 7373, 9587, 20684, 2638, 21790, 18116, 1010, 13642, 2278, 2000, 10421, 14876, 2483, 2139, 24898, 2015, 8358, 3164, 2229, 1012, 102, 8292, 2015, 2689, 8163, 21877, 27346, 2102, 3802, 2890, 9530, 9153, 4570, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2139, 2777, 8780, 1011, 2605, 2474, 4606, 4013, 5403, 1010, 1077, 2175, 10087, 3077, 1090, 1010, 7505, 2474, 5715, 2139, 2175, 10087, 3077, 1011, 3393, 1996, 4014, 1010, 28616, 2063, 4372, 2326, 4372, 3851, 3802, 21864, 7367, 19817, 7140, 3726, 1037, 1023, 2463, 1037, 5285, 1040, 1005, 1051, 5562, 4887, 1010, 1010, 15068, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 9765, 2139, 2184, 1010, 1021, 6362, 3802, 2474, 18535, 3126, 2139, 13511, 2015, 2139, 6205, 2683, 1010, 1021, 3461, 10364, 2474, 2558, 2063, 3261, 1011, 2230, 1012, 102, 7505, 2474, 2276, 23879, 12898, 5856, 4226, 2010, 29469, 4226, 2474, 4606, 4013, 5403, 1010, 1077, 24188, 20431, 1516, 5003, 6279, 8743, 2271, 1090, 1010, 7505, 2474, 5715, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 28616, 2063, 4372, 2326, 4372, 4437, 3802, 1037, 2539, 2463, 1010, 2474, 4860, 9587, 20684, 2638, 5754, 16284, 2571, 23408, 4747, 5657, 2139, 2184, 1010, 1018, 6362, 10364, 2474, 2558, 2063, 3411, 1011, 2456, 1037, 2184, 1010, 1021, 6362, 10364, 3261, 1011, 2230, 1010, 16405, 2483, 1037, 2340, 1010, 1015, 6362, 10364, 2889, 1011, 12609, 1012, 102, 13075, 7140, 3077, 9765, 16655, 5715, 3541, 2063, 1010, 2482, 15317, 26208, 2102, 2112, 2666, 4078, 16569, 21877, 2226, 15068, 24403, 21877, 2226, 9742, 2015, 1010, 8740, 12411, 2015, 2139, 2474, 26192, 15029, 2063, 2139, 7939, 28032, 2063, 2139, 1048, 1005, 16021, 4402, 1010, 1010, 1010, 1012, 102, 11968, 9932, 6216, 9236, 2474, 5715, 26208, 2102, 2112, 2666, 2139, 1048, 1005, 2250, 2063, 1040, 1005, 8432, 2139, 24188, 20431, 1011, 4372, 1011, 17155, 16778, 2078, 1010, 2123, 2102, 15317, 9765, 16655, 5715, 2139, 2474, 2522, 21017, 2638, 1012, 102, 8292, 4674, 2250, 2063, 1010, 21864, 19723, 22107, 2063, 6255, 16569, 1010, 9765, 4937, 20265, 29346, 2063, 18033, 4649, 9149, 2139, 2753, 2199, 1037, 25175, 3619, 2139, 3263, 2199, 10427, 11390, 1010, 1012, 102, 1048, 1005, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1010, 2425, 2063, 24209, 1005, 15317, 24501, 21748, 2102, 2139, 2474, 2918, 2139, 2123, 24045, 2015, 2885, 24336, 1040, 1521, 6139, 16012, 21281, 5332, 4226, 4078, 14017, 2015, 2522, 11467, 2455, 3104, 1006, 18856, 2278, 1007, 1010, 9765, 9388, 4226, 2063, 11968, 1048, 1005, 5197, 4078, 26568, 3406, 7442, 2015, 12943, 7277, 29111, 1006, 2531, 1003, 4372, 2760, 1007, 1010, 16655, 10817, 8909, 4765, 7413, 1037, 3526, 2063, 2139, 2901, 1006, 2531, 1003, 1007, 1012, 102, 2474, 16360, 8445, 22753, 6987, 10559, 4372, 2760, 9765, 2474, 24086, 18941, 2063, 1024, 10996, 2015, 1006, 4805, 1003, 1007, 1010, 25170, 2015, 5424, 4244, 1006, 4229, 1010, 1019, 1003, 1007, 1010, 10019, 12943, 7277, 29111, 21770, 10624, 6914, 2229, 1006, 2321, 1010, 1019, 1003, 1007, 1012, 102, 1048, 1005, 16270, 2777, 11968, 9932, 6216, 9236, 1037, 22137, 4895, 2041, 4014, 4372, 5622, 10177, 2566, 11368, 5794, 2102, 2139, 12826, 2099, 1048, 1521, 6622, 18033, 3393, 29023, 2139, 1048, 1521, 6139, 4078, 14017, 2015, 2139, 2474, 5715, 1006, 15068, 2139, 26568, 3406, 7442, 2015, 1037, 4078, 14925, 18223, 2229, 2367, 2229, 1007, 1012, 102, 4606, 17301, 2869, 4958, 2080, 10997, 2365, 2102, 7801, 2015, 27411, 2433, 2063, 2139, 11122, 2229, 15068, 7760, 29347, 23144, 5267, 1024, 2474, 11122, 2063, 2139, 16220, 5498, 1006, 16855, 6137, 2063, 9033, 8586, 2571, 1007, 1010, 2474, 11122, 2063, 1040, 1005, 17997, 1011, 2350, 1006, 11102, 1011, 7647, 1007, 3802, 2474, 2558, 2063, 2552, 16284, 2571, 1006, 3925, 1037, 8740, 23099, 4103, 1005, 17504, 1007, 1012, 102, 3393, 2053, 2213, 2139, 2474, 2334, 4221, 9765, 2012, 22199, 2063, 27411, 4649]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nLa commune est au nord-est du Cotentin. Son bourg est à 2,5 km à l'est de Saint-Pierre-Église et à 8 km à l'ouest de Barfleur.\\n\\n\\nLe climat qui caractérise la commune est qualifié, en 2010, de « climat océanique franc », selon la typologie des climats de la France qui compte alors huit grands types de climats en métropole. En 2020, la commune ressort du type « climat océanique » dans la classification établie par Météo-France, qui ne compte désormais, en première approche, que cinq grands types de climats en métropole. Ce type de climat se traduit par des températures douces et une pluviométrie relativement abondante (en liaison avec les perturbations venant de l'Atlantique), répartie tout au long de l'année avec un léger maximum d'octobre à février.\\nLes paramètres climatiques qui ont permis d’établir la typologie de 2010 comportent six variables pour les températures et huit pour les précipitations, dont les valeurs correspondent à la normale 1971-2000. Les sept principales variables caractérisant la commune sont présentées dans l'encadré ci-après.\\n\\nAvec le changement climatique, ces variables ont évolué. Une étude réalisée en 2014 par la Direction générale de l'Énergie et du Climat complétée par des études régionales prévoit en effet que la température moyenne devrait croître et la pluviométrie moyenne baisser, avec toutefois de fortes variations régionales. Ces changements peuvent être constatés sur la station météorologique de Météo-France la plus proche, « Gonneville », sur la commune de Gonneville-Le Theil, mise en service en 1959 et qui se trouve à 9 km à vol d'oiseau,, où la température moyenne annuelle est de 10,7 °C et la hauteur de précipitations de 919,7 mm pour la période 1981-2010.\\nSur la station météorologique historique la plus proche, « Cherbourg – Maupertus », sur la commune de Cherbourg-en-Cotentin, mise en service en 1935 et à 19 km, la température moyenne annuelle évolue de 10,4 °C pour la période 1971-2000 à 10,7 °C pour 1981-2010, puis à 11,1 °C pour 1991-2020.\\n\\n\\n\\n\\nVarouville est une commune rurale, car elle fait partie des communes peu ou très peu denses, au sens de la grille communale de densité de l'Insee,,,.\\nPar ailleurs la commune fait partie de l'aire d'attraction de Cherbourg-en-Cotentin, dont elle est une commune de la couronne. Cette aire, qui regroupe 77 communes, est catégorisée dans les aires de 50 000 à moins de 200 000 habitants,.\\n\\n\\n\\nL'occupation des sols de la commune, telle qu'elle ressort de la base de données européenne d’occupation biophysique des sols Corine Land Cover (CLC), est marquée par l'importance des territoires agricoles (100 % en 2018), une proportion identique à celle de 1990 (100 %). La répartition détaillée en 2018 est la suivante : prairies (46 %), terres arables (38,5 %), zones agricoles hétérogènes (15,5 %).\\nL'IGN met par ailleurs à disposition un outil en ligne permettant de comparer l’évolution dans le temps de l’occupation des sols de la commune (ou de territoires à des échelles différentes). Plusieurs époques sont accessibles sous forme de cartes ou photos aériennes : la carte de Cassini (XVIIIe siècle), la carte d'état-major (1820-1866) et la période actuelle (1950 à aujourd'hui).\\n\\n\\nLe nom de la localité est attesté sous les formes Vasrouvilla (sans date), Warouvilla en 1280, Varrouvilla vers 1280.\\nLe toponyme est basé sur un anthroponyme germanique tel que Warald ou Warulfus,, (forme latinisée, comprendre Warulf/Warolf cf. Warulfe Ier d'Uxelles) et sur l'ancien français ville/vile dans son sens originel de « domaine rural » issu du latin villa rustica.\\nRemarque : le même nom de personne est attesté au moins une seconde fois en Normandie dans Montgaroult (Orne, Mons Warulfi 1063), cette commune se trouvant au sud de l'isoglosse w- / g(u)- (qui est parallèle à la ligne Joret en Normandie), d'où le passage de [w] > [g], alors que dans Varouville, il s'agit de l'évolution secondaire [w] > [v] qui s'est produite seulement à partir du XIIe siècle.\\nLe gentilé est Varouvillais.\\n\\n\\nEntre 1911 et 1950, la commune est traversée par le « Tue-Vaques », le chemin de fer entre Cherbourg et Barfleur, dont on peut encore voir l'ancienne gare à l'architecture du XXe siècle, près de l'église.\\n\\n\\n\\nLe conseil municipal est composé de onze membres dont le maire et deux adjoints.\\n\\n\\nL'évolution du nombre d'habitants est connue à travers les recensements de la population effectués dans la commune depuis 1793. À partir de 2006, les populations légales des communes sont publiées annuellement par l'Insee. Le recensement repose désormais sur une collecte d'information annuelle, concernant successivement tous les territoires communaux au cours d'une période de cinq ans. Pour les communes de moins de 10 000 habitants, une enquête de recensement portant sur toute la population est réalisée tous les cinq ans, les populations légales des années intermédiaires étant quant à elles estimées par interpolation ou extrapolation. Pour la commune, le premier recensement exhaustif entrant dans le cadre du nouveau dispositif a été réalisé en 2005.\\nEn 2020, la commune comptait 233 habitants, en diminution de 12,08 % par rapport à 2014 (Manche : −0,97 %, France hors Mayotte : +1,9 %).\\nVarouville a compté jusqu'à 519 habitants en 1806.\\n\\n\\n\\n\\n\\nÉglise Saint-Martin (XIIIe siècle) avec son clocher en bâtière bâti en 1710, dont le mobilier fut fortement endommagé pendant la Révolution. Elle abrite une sculpture charité Saint-Martin avec donateur en pierre calcaire de la fin du XVe classée au titre objet aux monuments historiques. Elle formait à l'origine tympan au-dessus de la porte d'entrée de l'église et fut déplacée à l'intérieur de la nef afin d'être mieux conservée. Le donateur sans tête est représenté en prière, avec probablement son épouse derrière lui, à gauche du groupe sculpté. .\\nChâteau de la Bréhoulle.\\nAncienne gare, près de l'église, de la ligne de chemin de fer de Cherbourg à Barfleur où s'arrêtait le « tue-vaques ».\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"flat_contents\"][df_train.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3002, 1011, 5578, 1011, 1041, 25394, 3366]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.encode(\"Saint-Pierre-Église\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"labels_ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "10\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "14\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(sum(train_dataset[i][\"labels_ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID du token [SEP]: 102\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "\n",
    "print(f\"ID du token [SEP]: {sep_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "  print(len(train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
